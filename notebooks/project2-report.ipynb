{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "## MSDS 7349 - Section 401\n",
    "## Project 2\n",
    "\n",
    "[Data Science @ Southern Methodist University](https://datascience.smu.edu/)\n",
    "\n",
    "# Table of Contents\n",
    "* [Team Members](#Team-Members)\n",
    "* [Data Preparation](#Data-Preparation)\n",
    "* [Dataset Description](#Dataset-Description)\n",
    "* [Evaluation Metrics Description](#Evaluation-Metrics-Description)\n",
    "* [Training and Testing Splits method](#Training-Testing)\n",
    "* [Classification Task](#Classification-Task)\n",
    "* [Regression Task](#Regression-Task)\n",
    "* [Methods of Evaluation Results](#Methods-of-Evaluation)\n",
    "* [Advantages of each model](#Advantages-of-each-model)\n",
    "* [Relevant Attributes](#Relevant-Attributes)\n",
    "* [Deployment](#Deployment)\n",
    "* [Exceptional Work](#Exceptional-Work)\n",
    "* [References](#References)\n",
    "\n",
    "\n",
    "# <a name=\"Team-Members\"></a>Team Members\n",
    "* [Jostein Barry-Straume](https://github.com/josteinstraume)\n",
    "* [Kevin Cannon](https://github.com/kcannon2)\n",
    "* [Ernesto Carrera Ruvalcaba](https://github.com/ecarrerasmu)\n",
    "* [Adam Tschannen](https://github.com/adamtschannen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Data-Preparation\"></a>Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n",
    "\n",
    "> The credit default data set is from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients#). It has 30,000 records with 24 attributes. The records reflect the payment data from an important Taiwanese bank during October, 2005 (Yeh & Lien 2475).\n",
    "\n",
    "> The purpose of the data set was to tackle the issue of forecasting the probability of default. In particular, the researchers of this data set sought to determine if the \"estimated probability of default produced from data mining methods... (could) represent the \"real\" probability of default\" (Yeh & Lien 2473).\n",
    "\n",
    "> The dataset needs some pre-processing before it is ready for classification and regression analysis.\n",
    "\n",
    "> To start, missing or incorrect values for education level, marital status, and repayment status are imputed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import statistics as st\n",
    "import csv as csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from __future__ import print_function\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "filepath = \"/data/credit-defaults.xls\"\n",
    "\n",
    "# Relative local path to avoid changing filepath constantly\n",
    "credit = pd.read_excel('../data/credit-defaults.xls', header=1, skiprows=0)\n",
    "\n",
    "\n",
    "# Rename column(s)\n",
    "credit = credit.rename(columns={'default payment next month': 'default_next_m', 'PAY_0': 'PAY_1'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING NEW VARIABLE TO IMPUTE THE VALUES TO 4, THAT REPRESENTS OTHER\n",
    "credit['EDUCATION_INP']=credit['EDUCATION']\n",
    "\n",
    "credit.loc[credit['EDUCATION'] > 4, 'EDUCATION_INP'] = 4\n",
    "credit.loc[credit['EDUCATION'] == 0, 'EDUCATION_INP'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "####FOR MARRIAGE\n",
    "#CREATING NEW VARIABLE TO IMPUTE THE VALUES TO 2, THAT REPRESETNS SINGLE, since the value of 0 is not defined in\n",
    "#the data dictionary\n",
    "credit['MARRIAGE_INP']=credit['MARRIAGE']\n",
    "\n",
    "\n",
    "credit.loc[credit['MARRIAGE'] == 0, 'MARRIAGE_INP'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### CREATING A FUNCTION TO GROUP VARIABLES\n",
    "def group_biv_v1(var_name,RangeName,CutOff,NumBins,BinLabel,var_x,var_y,title1,title2):\n",
    "#def bivariate_v1(NumBins): \n",
    "    #Creating the BINS\n",
    "    credit[RangeName]=pd.cut(var_name,CutOff,NumBins,labels=BinLabel)\n",
    "    #Grouping by the BINS variable\n",
    "    default_g=credit.groupby(by=[RangeName])\n",
    "    #% of POPULATION\n",
    "    bins_percentage=default_g[RangeName].count()/credit[RangeName].count()\n",
    "    \n",
    "    #### creating DUMMY VARIABLES\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#group_biv_v1(credit.PAY_1,'PAY_1_range',[-2.1,0,1,10],3,['Pay duly','delay 1 month ','delay > 1'],'Percentage','PAY_1_bins','% of population PAY_1','Default PAY_1 ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## IMPUTE VALUES FOR THE VARIABLES OF REPAYMENT STATUS (PAY0, PAY1,   PAYN)\n",
    "group_biv_v1(credit.PAY_1,'PAY_1_range',[-2.1,0,1,10],3,['Pay duly','delay 1 month ','delay > 1'],'Percentage','PAY_1_bins','% of population PAY_1','Default PAY_1 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_2,'PAY_2_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_2_bins','% of population PAY_2','Default PAY_2 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_3,'PAY_3_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_3_bins','% of population PAY_3','Default PAY_3 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_4,'PAY_4_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_4_bins','% of population PAY_4','Default PAY_4 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_5,'PAY_5_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_5_bins','% of population PAY_5','Default PAY_5 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_6,'PAY_6_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_6_bins','% of population PAY_6','Default PAY_6 ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default_next_m</th>\n",
       "      <th>EDUCATION_INP</th>\n",
       "      <th>MARRIAGE_INP</th>\n",
       "      <th>PAY_1_range</th>\n",
       "      <th>PAY_2_range</th>\n",
       "      <th>PAY_3_range</th>\n",
       "      <th>PAY_4_range</th>\n",
       "      <th>PAY_5_range</th>\n",
       "      <th>PAY_6_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "      ...       PAY_AMT6  default_next_m  EDUCATION_INP  MARRIAGE_INP  \\\n",
       "0     ...              0               1              2             1   \n",
       "1     ...           2000               1              2             2   \n",
       "2     ...           5000               0              2             2   \n",
       "3     ...           1000               0              2             1   \n",
       "4     ...            679               0              2             1   \n",
       "\n",
       "   PAY_1_range  PAY_2_range  PAY_3_range  PAY_4_range  PAY_5_range  \\\n",
       "0    delay > 1    delay > 1     Pay duly     Pay duly     Pay duly   \n",
       "1     Pay duly    delay > 1     Pay duly     Pay duly     Pay duly   \n",
       "2     Pay duly     Pay duly     Pay duly     Pay duly     Pay duly   \n",
       "3     Pay duly     Pay duly     Pay duly     Pay duly     Pay duly   \n",
       "4     Pay duly     Pay duly     Pay duly     Pay duly     Pay duly   \n",
       "\n",
       "   PAY_6_range  \n",
       "0     Pay duly  \n",
       "1    delay > 1  \n",
       "2     Pay duly  \n",
       "3     Pay duly  \n",
       "4     Pay duly  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 33 columns):\n",
      "ID                30000 non-null int64\n",
      "LIMIT_BAL         30000 non-null int64\n",
      "SEX               30000 non-null int64\n",
      "EDUCATION         30000 non-null int64\n",
      "MARRIAGE          30000 non-null int64\n",
      "AGE               30000 non-null int64\n",
      "PAY_1             30000 non-null int64\n",
      "PAY_2             30000 non-null int64\n",
      "PAY_3             30000 non-null int64\n",
      "PAY_4             30000 non-null int64\n",
      "PAY_5             30000 non-null int64\n",
      "PAY_6             30000 non-null int64\n",
      "BILL_AMT1         30000 non-null int64\n",
      "BILL_AMT2         30000 non-null int64\n",
      "BILL_AMT3         30000 non-null int64\n",
      "BILL_AMT4         30000 non-null int64\n",
      "BILL_AMT5         30000 non-null int64\n",
      "BILL_AMT6         30000 non-null int64\n",
      "PAY_AMT1          30000 non-null int64\n",
      "PAY_AMT2          30000 non-null int64\n",
      "PAY_AMT3          30000 non-null int64\n",
      "PAY_AMT4          30000 non-null int64\n",
      "PAY_AMT5          30000 non-null int64\n",
      "PAY_AMT6          30000 non-null int64\n",
      "default_next_m    30000 non-null int64\n",
      "EDUCATION_INP     30000 non-null int64\n",
      "MARRIAGE_INP      30000 non-null int64\n",
      "PAY_1_range       30000 non-null category\n",
      "PAY_2_range       30000 non-null category\n",
      "PAY_3_range       30000 non-null category\n",
      "PAY_4_range       30000 non-null category\n",
      "PAY_5_range       30000 non-null category\n",
      "PAY_6_range       30000 non-null category\n",
      "dtypes: category(6), int64(27)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 37 columns):\n",
      "ID                            30000 non-null int64\n",
      "LIMIT_BAL                     30000 non-null int64\n",
      "EDUCATION                     30000 non-null int64\n",
      "MARRIAGE                      30000 non-null int64\n",
      "AGE                           30000 non-null int64\n",
      "PAY_1                         30000 non-null int64\n",
      "PAY_2                         30000 non-null int64\n",
      "PAY_3                         30000 non-null int64\n",
      "PAY_4                         30000 non-null int64\n",
      "PAY_5                         30000 non-null int64\n",
      "PAY_6                         30000 non-null int64\n",
      "BILL_AMT1                     30000 non-null int64\n",
      "BILL_AMT2                     30000 non-null int64\n",
      "BILL_AMT3                     30000 non-null int64\n",
      "BILL_AMT4                     30000 non-null int64\n",
      "BILL_AMT5                     30000 non-null int64\n",
      "BILL_AMT6                     30000 non-null int64\n",
      "PAY_AMT1                      30000 non-null int64\n",
      "PAY_AMT2                      30000 non-null int64\n",
      "PAY_AMT3                      30000 non-null int64\n",
      "PAY_AMT4                      30000 non-null int64\n",
      "PAY_AMT5                      30000 non-null int64\n",
      "PAY_AMT6                      30000 non-null int64\n",
      "default_next_m                30000 non-null int64\n",
      "EDUCATION_INP_2               30000 non-null uint8\n",
      "EDUCATION_INP_3               30000 non-null uint8\n",
      "EDUCATION_INP_4               30000 non-null uint8\n",
      "MARRIAGE_INP_2                30000 non-null uint8\n",
      "MARRIAGE_INP_3                30000 non-null uint8\n",
      "PAY_1_range_delay 1 month     30000 non-null uint8\n",
      "PAY_1_range_delay > 1         30000 non-null uint8\n",
      "PAY_2_range_delay > 1         30000 non-null uint8\n",
      "PAY_3_range_delay > 1         30000 non-null uint8\n",
      "PAY_4_range_delay > 1         30000 non-null uint8\n",
      "PAY_5_range_delay > 1         30000 non-null uint8\n",
      "PAY_6_range_delay > 1         30000 non-null uint8\n",
      "SEX_2                         30000 non-null uint8\n",
      "dtypes: int64(24), uint8(13)\n",
      "memory usage: 5.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>MARRIAGE_INP_2</th>\n",
       "      <th>MARRIAGE_INP_3</th>\n",
       "      <th>PAY_1_range_delay 1 month</th>\n",
       "      <th>PAY_1_range_delay &gt; 1</th>\n",
       "      <th>PAY_2_range_delay &gt; 1</th>\n",
       "      <th>PAY_3_range_delay &gt; 1</th>\n",
       "      <th>PAY_4_range_delay &gt; 1</th>\n",
       "      <th>PAY_5_range_delay &gt; 1</th>\n",
       "      <th>PAY_6_range_delay &gt; 1</th>\n",
       "      <th>SEX_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  PAY_5  \\\n",
       "0   1      20000          2         1   24      2      2     -1     -1     -2   \n",
       "1   2     120000          2         2   26     -1      2      0      0      0   \n",
       "2   3      90000          2         2   34      0      0      0      0      0   \n",
       "3   4      50000          2         1   37      0      0      0      0      0   \n",
       "4   5      50000          2         1   57     -1      0     -1      0      0   \n",
       "\n",
       "   ...    MARRIAGE_INP_2  MARRIAGE_INP_3  PAY_1_range_delay 1 month   \\\n",
       "0  ...                 0               0                           0   \n",
       "1  ...                 1               0                           0   \n",
       "2  ...                 1               0                           0   \n",
       "3  ...                 0               0                           0   \n",
       "4  ...                 0               0                           0   \n",
       "\n",
       "   PAY_1_range_delay > 1  PAY_2_range_delay > 1  PAY_3_range_delay > 1  \\\n",
       "0                      1                      1                      0   \n",
       "1                      0                      1                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   PAY_4_range_delay > 1  PAY_5_range_delay > 1  PAY_6_range_delay > 1  SEX_2  \n",
       "0                      0                      0                      0      1  \n",
       "1                      0                      0                      1      1  \n",
       "2                      0                      0                      0      1  \n",
       "3                      0                      0                      0      1  \n",
       "4                      0                      0                      0      0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CREATE DUMMY VARIABLES\n",
    "#Convert Categorical fields to bool using get_dummies\n",
    "#Use drop_first=true to aviod multicolinierarity\n",
    "### The drop_first=true eliminates the first group of the dummy variable\n",
    "### According to the notes provided of the professor we do this to prevent multicollinearity\n",
    "#### I can see it in the context of regression and logistic regression. We may want to select the group to delet\n",
    "##### The method \"get_dummies\" also ELIMINATES THE ORIGINAL VARIABLE TO CREATE THE dummies\n",
    "\n",
    "#EC: Creating  another reference in MEMORY, so the changes in df will not be REFLECTED IN CREDIT\n",
    "df = credit.copy()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.get_dummies(data=credit, \n",
    "                       columns=['EDUCATION_INP',\n",
    "                                'MARRIAGE_INP', \n",
    "                                'PAY_1_range',\n",
    "                                'PAY_2_range',\n",
    "                                'PAY_3_range',\n",
    "                                'PAY_4_range',\n",
    "                                'PAY_5_range',\n",
    "                                'PAY_6_range',\n",
    "                                'SEX'], drop_first=True) #Try drop_first=true to aviod multicolinierarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "#credit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Next, additional variables are created to help with the regression and classification analysis. The following variables were created and added to the dataset:\n",
    "* Average bill amount over the 6 month period\n",
    "* Average payment amount over the 6 month period\n",
    "* Ratio of average bill amount to credit limit balance\n",
    "* Ratio of the average payment amount to credit limit balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 41 columns):\n",
      "ID                            30000 non-null int64\n",
      "LIMIT_BAL                     30000 non-null int64\n",
      "EDUCATION                     30000 non-null int64\n",
      "MARRIAGE                      30000 non-null int64\n",
      "AGE                           30000 non-null int64\n",
      "PAY_1                         30000 non-null int64\n",
      "PAY_2                         30000 non-null int64\n",
      "PAY_3                         30000 non-null int64\n",
      "PAY_4                         30000 non-null int64\n",
      "PAY_5                         30000 non-null int64\n",
      "PAY_6                         30000 non-null int64\n",
      "BILL_AMT1                     30000 non-null int64\n",
      "BILL_AMT2                     30000 non-null int64\n",
      "BILL_AMT3                     30000 non-null int64\n",
      "BILL_AMT4                     30000 non-null int64\n",
      "BILL_AMT5                     30000 non-null int64\n",
      "BILL_AMT6                     30000 non-null int64\n",
      "PAY_AMT1                      30000 non-null int64\n",
      "PAY_AMT2                      30000 non-null int64\n",
      "PAY_AMT3                      30000 non-null int64\n",
      "PAY_AMT4                      30000 non-null int64\n",
      "PAY_AMT5                      30000 non-null int64\n",
      "PAY_AMT6                      30000 non-null int64\n",
      "default_next_m                30000 non-null int64\n",
      "EDUCATION_INP_2               30000 non-null uint8\n",
      "EDUCATION_INP_3               30000 non-null uint8\n",
      "EDUCATION_INP_4               30000 non-null uint8\n",
      "MARRIAGE_INP_2                30000 non-null uint8\n",
      "MARRIAGE_INP_3                30000 non-null uint8\n",
      "PAY_1_range_delay 1 month     30000 non-null uint8\n",
      "PAY_1_range_delay > 1         30000 non-null uint8\n",
      "PAY_2_range_delay > 1         30000 non-null uint8\n",
      "PAY_3_range_delay > 1         30000 non-null uint8\n",
      "PAY_4_range_delay > 1         30000 non-null uint8\n",
      "PAY_5_range_delay > 1         30000 non-null uint8\n",
      "PAY_6_range_delay > 1         30000 non-null uint8\n",
      "SEX_2                         30000 non-null uint8\n",
      "Avg_BILL                      30000 non-null float64\n",
      "Avg_PAY                       30000 non-null float64\n",
      "AvgBill_to_LIMIT_BAL          30000 non-null float64\n",
      "AvgPay_to_LIMIT_BAL           30000 non-null float64\n",
      "dtypes: float64(4), int64(24), uint8(13)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "##### CREATING ADDITIONAL VARIABLES \n",
    "\n",
    "############## CREATING NEW VARIABLES\n",
    "\n",
    "#Average of the bill amount\n",
    "df['Avg_BILL']=(df['BILL_AMT1']+df['BILL_AMT2']+df['BILL_AMT3']+ df['BILL_AMT4']+df['BILL_AMT5']+df['BILL_AMT6']\n",
    "               )/float(6)\n",
    "\n",
    "\n",
    "#Average of the Payment amount\n",
    "\n",
    "df['Avg_PAY']=(df['PAY_AMT1']+df['PAY_AMT2']+df['PAY_AMT3']+df['PAY_AMT4']+df['PAY_AMT5']+df['PAY_AMT6']\n",
    "               )/float(6)\n",
    "\n",
    "#We are constructing the ratio with the average BILL AMOUNT TO LIMIT\n",
    "df['AvgBill_to_LIMIT_BAL']=(df['Avg_BILL']/df['LIMIT_BAL'])\n",
    "\n",
    "\n",
    "#We are constructing the ratio with the  average PAYMENT AMOUNT TO LIMIT\n",
    "df['AvgPay_to_LIMIT_BAL']=(df['Avg_PAY']/df['LIMIT_BAL'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing variables not needed in the analysis\n",
    ">We will conduct one classification task and one regression task. We will create 2 different objects since we will remove different variables\n",
    "\n",
    "> We first create the object for the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WE CREATE AN OBJECT FOR THE CLASSIFICATION TASK AND OTHER FOR THE REGRESSION TASK\n",
    "\n",
    "# CREATING THE OBJECT FOR THE CLASSIFICATION TASK\n",
    "class_t=df.copy()\n",
    "\n",
    "\n",
    "if 'default_next_m' in class_t:\n",
    "    y_c = class_t['default_next_m'].values\n",
    "    del class_t['default_next_m']\n",
    "    del class_t['ID']\n",
    "    del class_t['EDUCATION']\n",
    "    del class_t['MARRIAGE']\n",
    "    del class_t['PAY_1']\n",
    "    del class_t['PAY_2']\n",
    "    del class_t['PAY_3']\n",
    "    del class_t['PAY_4']\n",
    "    del class_t['PAY_5']\n",
    "    del class_t['PAY_6']\n",
    "    X_c = class_t.values\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then we create the object for the Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0642    ,  0.02371806,  0.1882463 , ...,  0.39164444,\n",
       "        0.55543958,  0.76958   ])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WE CREATE AN OBJECT FOR THE CLASSIFICATION TASK AND OTHER FOR THE REGRESSION TASK\n",
    "\n",
    "# CREATING THE OBJECT FOR THE REGRESSION  TASK\n",
    "\n",
    "reg_t=df.copy()\n",
    "\n",
    "\n",
    "if 'AvgBill_to_LIMIT_BAL' in reg_t:\n",
    "    y_r = reg_t['AvgBill_to_LIMIT_BAL'].values\n",
    "    del reg_t['AvgBill_to_LIMIT_BAL']\n",
    "    del reg_t['ID']\n",
    "    del reg_t['EDUCATION']\n",
    "    del reg_t['MARRIAGE']\n",
    "    del reg_t['PAY_1']\n",
    "    del reg_t['PAY_2']\n",
    "    del reg_t['PAY_3']\n",
    "    del reg_t['PAY_4']\n",
    "    del reg_t['PAY_5']\n",
    "    del reg_t['PAY_6']\n",
    "    del reg_t['Avg_BILL']\n",
    "    del reg_t['LIMIT_BAL']\n",
    "    del reg_t['AvgPay_to_LIMIT_BAL']\n",
    "    del reg_t['BILL_AMT1']\n",
    "    del reg_t['BILL_AMT2']\n",
    "    del reg_t['BILL_AMT3']\n",
    "    del reg_t['BILL_AMT4']\n",
    "    del reg_t['BILL_AMT5']\n",
    "    del reg_t['BILL_AMT6']\n",
    "    X_r = reg_t.values\n",
    "\n",
    "#len(y_r)\n",
    "y_r\n",
    "#reg_t.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Dataset-Description\"></a>Dataset Description\n",
    "\n",
    ">[5 points] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created).\n",
    "\n",
    "# <a name=\"Data-Meaning-Type\"></a>Data Meaning Type\n",
    "*Describe the meaning and type of data (scale, values, etc.) for each attribute in the data file.*\n",
    "\n",
    "> The original dataset contains the following data types:\n",
    "\n",
    "| Variable | Variable Type | Description |\n",
    "| :------: | :-----------: | :----- |\n",
    "| LIMIT_BAL | int64 | The amount of the given credit in New Taiwan dollars.<br/>It includes both the individual consumer credit and his/her family (supplementary) credit |\n",
    "| SEX | int64 | Defines each subjects gender with:<ul><li>1 = Male</li><li>2 = Female</li></ul> |\n",
    "| EDUCATION | int64 | Represents each subject level of education with:<ul><li>1 = Graduate School</li><li>2 = University</li><li>3 = High School</li><li>4 = Other</li></ul> |\n",
    "| MARRIAGE | int64 | Defines the person's relationship status by:<ul><li>1 = Married</li><li>2 = Single</li><li>3 = Other</li></ul> |\n",
    "| AGE | int64 | Defines how old each person is in years |\n",
    "| PAY_0 | int64 | The repayment status in September, 2005 |\n",
    "| PAY_2 | int64 | The repayment status in August, 2005 |\n",
    "| PAY_3 | int64 | The repayment status in July, 2005 |\n",
    "| PAY_4 | int64 | The repayment status in June, 2005 |\n",
    "| PAY_5 | int64 | The repayment status in May, 2005 |\n",
    "| PAY_6 | int64 | The repayment status in April, 2005 |\n",
    "| BILL_AMT1 | int64 | The repayment status in September, 2005 |\n",
    "| BILL_AMT2 | int64 | The repayment status in August, 2005 |\n",
    "| BILL_AMT3 | int64 | The repayment status in July, 2005 |\n",
    "| BILL_AMT4 | int64 | The repayment status in June, 2005 |\n",
    "| BILL_AMT5 | int64 | The repayment status in May, 2005 |\n",
    "| BILL_AMT6 | int64 | The repayment status in April, 2005 |\n",
    "| PAY_AMT1 | int64 | The amount paid in September, 2005 |\n",
    "| PAY_AMT2 | int64 | The amount paid in August, 2005 |\n",
    "| PAY_AMT3 | int64 | The amount paid in July, 2005 |\n",
    "| PAY_AMT4 | int64 | The amount paid in June, 2005 |\n",
    "| PAY_AMT5 | int64 | The amount paid in May, 2005 |\n",
    "| PAY_AMT6 | int64 | The amount paid in April, 2005 |\n",
    "| default payment next month | int64 | A binary value indicating default status with:<ul><li>0 = Customer has defaulted</li><li>1 = Customer has not defaulted</li></ul>|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The following table exhibit the name of the variables with imputed values and the dummy variables for the categorical variables.\n",
    "\n",
    "\n",
    "| Variable | Variable Type | Description |\n",
    "| :------: | :-----------: | :----- |\n",
    "| EDUCATION_INP_2 | uint8 | Dummy variable for education - indicating university grade|\n",
    "| EDUCATION_INP_3 | uint8| Dummy variable for education - indicating high school grade |\n",
    "| EDUCATION_INP_4 | uint8 |  Dummy variable for education - indicating high school grade |\n",
    "| MARRIAGE_INP_2 | uint8 |  Dummy variable for marital status - indicating married |\n",
    "| MARRIAGE_INP_3 | uint8 | Dummy variable for marital status - indicating other |\n",
    "| PAY_1_range_delay 1 month | uint8 | Dummy indicating 1 month delay for September, 2005 |\n",
    "| PAY_1_range_delay > 1 | uint8 | Dummy indicating more than 2 month delay for September, 2005 |\n",
    "| PAY_2_range_delay > 1  | uint8 | Dummy indicating more than 2 month delay for August, 2005 |\n",
    "| PAY_3_range_delay > 1  | uint8 | Dummy indicating more than 2 month delay for July, 2005 |\n",
    "| PAY_4_range_delay > 1  | uint8 | Dummy indicating more than 2 month delay for June, 2005 |\n",
    "| PAY_5_range_delay > 1  | uint8 | Dummy indicating more than 2 month delay for May, 2005 |\n",
    "| PAY_6_range_delay > 1  | uint8 | Dummy indicating more than 2 month delay for April, 2005 |\n",
    "| SEX_2 | uint8 | Dummy variable for sex - indicating female|\n",
    "| Avg_BILL | float64 | Average bill amount over the 6 month period |\n",
    "| Avg_PAY | float64 | Average payment amount over the 6 month period|\n",
    "| AvgBill_to_LIMIT_BAL | float64 | Ratio of average bill amount to credit limit balance |\n",
    "| AvgPay_to_LIMIT_BAL | float64 | Ratio of the average payment amount to credit limit balance |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description for the classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To complete the classification task, we removed columns: 'default_next_m', 'ID','EDUCATION', \"MARRIAGE', and the payment status 'PAY_1 -PAY_6'. The remaining variables include age, payment amounts, default status for next month, the imputed values of education and marital status, delay in repayment status, sex, and average payment amount. The four new created variables, as mentioned above, were added to the classification dataset as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description for the Regression task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> To complete the regression task, several columns were removed: 'ID', 'EDUCATION', 'MARRIAGE', 'PAY_1' through 'PAY_6', 'Avg_BILL', 'LIMIT_BAL', 'AvgPay_to_LIMIT_BAL', and 'BILL_AMT1' through 'BILL_AMT6'. The remaining variables include age, payment amounts, default status for next month, the imputed values of education and marital status, delay in repayment status, sex, and average payment amount. Two of the four new created variables, 'Avg_PAY' and 'AvgBill_to_LIMIT_BAL', were added to the regression dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Evaluation-Metrics-Description\"></a>Evaluation Metrics Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">[10 points] Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Evaluating Regression Models \n",
    "\n",
    "**All regression models created in this notebook are validated using the following metrics:**\n",
    "* Mean Absolute Error (MAE) - https://www.quora.com/Are-there-instances-where-root-mean-squared-error-might-be-used-rather-than-mean-absolute-error\n",
    "* Root Mean Squared Error (RMSE) - https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "* Mean Absolute Percentage Error (MAPE) - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "\n",
    "**For details on making scorers to return multiple mean error scores see:**\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html\n",
    "* https://github.com/scikit-learn/scikit-learn/pull/7388\n",
    "* https://github.com/drorata/multiscorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The metrics mentioned above are appropriate for the Regression task since they measure the error of our model. We are calculating the 3 metrics since they can be used differently depending on the usage of the model,the underlying data and they all have specific drawbacks. \n",
    "\n",
    ">RMSE gives a relatively high weight to large errors. This means the RMSE is most useful when large errors are particularly undesirable. For example, let's consider the case of a nuts and bolts manufacturing company. If the width specifications of say, the bolts are 8mm +- 0.1 mm, then any nut that is manufactured by the company with deviation > 0.1 mm is useless. Thus, higher errors are far more undesirable than lower.\n",
    "\n",
    "> One of the drawbacks of MAPE is that cannot be used if there are zero values (which sometimes happens for example in demand data) because there would be a division by zero.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for Evaluating Classification Models \n",
    "\n",
    "**All classification models created in this notebook are validated using the following metric:**\n",
    "* Recall - hhttp://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "\n",
    ">Recall is the ratio of correctly predicted positive observations to all observations in actual class \n",
    ">Recall is especially useful in the presence of unbalanced datasets (i.e. one category with very few observations). The proportion of defaulted borrowers is relatively low and therfore the recall is the metric deemed adequate to measure the performance of the classification task.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Training-Testing\"></a>Training and Testing Splits method\n",
    "\n",
    ">[10 points] Choose the method you will use for dividing your data into training and testing splits \n",
    "(i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is \n",
    "appropriate or use more than one method as appropriate. For example, \n",
    "if you are using time series data then you should be using continuous training and testing sets across time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classifications: We chose to use the stratified sampling method because our data contains a significantly high number of subjects classified as \"0\". Because of this imbalance, there is potential for the algorithm to predict a high number of true negatives and false negitives because of the class imbalance. The stratified cross validation procedure will ensure the training data sets will have approximately the same amount of subjects who defaulted as those who did not and will subsequently protect the algorithm against simpley predicting \"0\" everytime.\n",
    "\n",
    "For regression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINING THE CV OBJECT FOR CLASSIFICATION\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_cv_iterations = 10\n",
    "\n",
    "cv_object = StratifiedShuffleSplit(n_splits = num_cv_iterations, \n",
    "                            test_size = 0.20, train_size = 0.80, random_state=1)\n",
    "\n",
    "\n",
    "##### We generate the training and testing sample\n",
    "for train_indices, test_indices in cv_object.split(X_c,y_c): \n",
    "    X_c_train = X_c[train_indices]\n",
    "    y_c_train = y_c[train_indices]\n",
    "    \n",
    "    X_c_test = X_c[test_indices]\n",
    "    y_c_test = y_c[test_indices]\n",
    "\n",
    "\n",
    "#### SCALING THE OBJECTS\n",
    "    \n",
    "\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_c_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_c_train_scaled = scl_obj.transform(X_c_train) # apply to training\n",
    "X_c_test_scaled = scl_obj.transform(X_c_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINING THE CV OBJECT FOR REGRESSION\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "#cv = ShuffleSplit(n_splits=10, test_size=0.10, random_state=0)\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "num_cv_iterations = 10\n",
    "\n",
    "cv_reg = ShuffleSplit(n_splits = num_cv_iterations, \n",
    "                            test_size = 0.20, train_size = 0.80, random_state=1)\n",
    "\n",
    "\n",
    "##### We generate the training and testing sample\n",
    "for train_indices, test_indices in cv_reg.split(X_r,y_r): \n",
    "    X_r_train = X_r[train_indices]\n",
    "    y_r_train = y_r[train_indices]\n",
    "    \n",
    "    X_r_test = X_r[test_indices]\n",
    "    y_r_test = y_r[test_indices]\n",
    "    \n",
    "    \n",
    "    \n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj_r = StandardScaler()\n",
    "scl_obj_r.fit(X_r_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_r_train_scaled = scl_obj_r.transform(X_r_train) # apply to training\n",
    "X_r_test_scaled = scl_obj_r.transform(X_r_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "#cv_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Classification-Task\"></a>Classification Task\n",
    "\n",
    "> [20 points] Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification Objective\n",
    "> The purpose of the classification task will be to identify bad/delinquent borrowers in the bank's dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      " [[4111  562]\n",
      " [ 642  685]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 1\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87      4673\n",
      "          1       0.55      0.52      0.53      1327\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6000\n",
      "\n",
      "confusion matrix\n",
      " [[4121  552]\n",
      " [ 646  681]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 2\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.88      0.87      4673\n",
      "          1       0.55      0.51      0.53      1327\n",
      "\n",
      "avg / total       0.80      0.80      0.80      6000\n",
      "\n",
      "confusion matrix\n",
      " [[3960  713]\n",
      " [ 571  756]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 3\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86      4673\n",
      "          1       0.51      0.57      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.79      0.79      6000\n",
      "\n",
      "confusion matrix\n",
      " [[3895  778]\n",
      " [ 557  770]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 4\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.83      0.85      4673\n",
      "          1       0.50      0.58      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.78      0.78      6000\n",
      "\n",
      "confusion matrix\n",
      " [[3878  795]\n",
      " [ 543  784]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 5\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.85      4673\n",
      "          1       0.50      0.59      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.78      0.78      6000\n",
      "\n",
      "confusion matrix\n",
      " [[3913  760]\n",
      " [ 560  767]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 6\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.86      4673\n",
      "          1       0.50      0.58      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.78      0.79      6000\n",
      "\n",
      "confusion matrix\n",
      " [[3935  738]\n",
      " [ 558  769]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 7\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.84      0.86      4673\n",
      "          1       0.51      0.58      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.78      0.79      6000\n",
      "\n",
      "confusion matrix\n",
      " [[3943  730]\n",
      " [ 574  753]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 8\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.84      0.86      4673\n",
      "          1       0.51      0.57      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.78      0.79      6000\n",
      "\n",
      "confusion matrix\n",
      " [[3960  713]\n",
      " [ 578  749]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 9\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86      4673\n",
      "          1       0.51      0.56      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.78      0.79      6000\n",
      "\n",
      "confusion matrix\n",
      " [[4016  657]\n",
      " [ 590  737]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "\n",
      " *** Max Depths is 10\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.86      0.87      4673\n",
      "          1       0.53      0.56      0.54      1327\n",
      "\n",
      "avg / total       0.80      0.79      0.79      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Source:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "depths = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "for depth in depths:\n",
    "    clf = RandomForestClassifier(max_depth=depth, random_state=0, class_weight='balanced',\n",
    "                                max_features='auto', n_estimators=100, bootstrap=True)\n",
    "    model_rf = clf.fit(X_c_train, y_c_train)\n",
    "    y_hat = clf.predict(X_c_test)\n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_c_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_c_test,y_hat)\n",
    "    #print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "\n",
    "    print(\"\\n *** CLASSIFICATION REPORT ****\")\n",
    "    print(\"\\n *** Max Depths is\", depth)\n",
    "    #### CLASSIFICATION REPORT\n",
    "    ClassReport = mt.classification_report(y_c_test,y_hat)\n",
    "    print(ClassReport)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's see our changing the class_weight parameter to None impacts the precision and recall:\n",
      "\n",
      "Confusion matrix\n",
      " [[4415  258]\n",
      " [ 848  479]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.94      0.89      4673\n",
      "          1       0.65      0.36      0.46      1327\n",
      "\n",
      "avg / total       0.80      0.82      0.79      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Let\\'s see our changing the class_weight parameter to None impacts the precision and recall:\\n')\n",
    "clf = RandomForestClassifier(max_depth=None, min_samples_split=2, random_state=0, class_weight=None,\n",
    "                             max_features='auto', n_estimators=100, bootstrap=True)\n",
    "model_rf = clf.fit(X_c_train, y_c_train)\n",
    "y_hat = clf.predict(X_c_test)\n",
    "\n",
    "# now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "acc = mt.accuracy_score(y_c_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_c_test,y_hat)\n",
    "#print(\"accuracy\", acc )\n",
    "print(\"Confusion matrix\\n\",conf)\n",
    "\n",
    "print(\"\\n *** CLASSIFICATION REPORT ****\")\n",
    "#### CLASSIFICATION REPORT\n",
    "ClassReport = mt.classification_report(y_c_test,y_hat)\n",
    "print(ClassReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> By incrementally increasing the max_depths parameter we can see how the recall of the Random Forest classification model can be improved, albeit at the cost of precision. Around max_depths of 5 is when the decrease of precision outweighs the marginal increase in recall. Consequently, we will move on to adjusting parameters with a max_depths value of 5.\n",
    "\n",
    "> It appears that changing the class_weight parameter from 'balanced' to None detrimentally impacts the recall of classifying who is and isn't going to default on their credit. The input parameter for class_weight will remain as 'balanced.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      " [[3873  800]\n",
      " [ 548  779]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.83      0.85      4673\n",
      "          1       0.49      0.59      0.54      1327\n",
      "\n",
      "avg / total       0.79      0.78      0.78      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=5, min_samples_split=2, random_state=0, class_weight='balanced',\n",
    "                             max_features='auto', n_estimators=500, bootstrap=True)\n",
    "model_rf = clf.fit(X_c_train, y_c_train)\n",
    "y_hat = clf.predict(X_c_test)\n",
    "\n",
    "# now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "acc = mt.accuracy_score(y_c_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_c_test,y_hat)\n",
    "print(\"Confusion matrix\\n\",conf)\n",
    "\n",
    "print(\"\\n *** CLASSIFICATION REPORT ****\")\n",
    "#### CLASSIFICATION REPORT\n",
    "ClassReport = mt.classification_report(y_c_test,y_hat)\n",
    "print(ClassReport)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> After much tinkering, the model that offers the best balance between precision and recall involves the following input parameters:\n",
    "\n",
    "* Max depths of 5\n",
    "* Min_samples_split of 2\n",
    "* Balanced class_weight\n",
    "* 500 n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                             score\n",
      "PAY_1_range_delay > 1      0.265911\n",
      "PAY_2_range_delay > 1      0.177077\n",
      "PAY_3_range_delay > 1      0.0993419\n",
      "PAY_4_range_delay > 1      0.0668477\n",
      "PAY_5_range_delay > 1      0.0615964\n",
      "Avg_PAY                    0.0522552\n",
      "PAY_6_range_delay > 1      0.0390754\n",
      "PAY_AMT1                   0.0376743\n",
      "LIMIT_BAL                  0.0270168\n",
      "AvgBill_to_LIMIT_BAL       0.0266756\n",
      "PAY_AMT2                   0.0233533\n",
      "PAY_1_range_delay 1 month  0.0174449\n",
      "PAY_AMT3                   0.0164693\n",
      "PAY_AMT4                   0.0134557\n",
      "Avg_BILL                   0.013123\n",
      "PAY_AMT6                   0.0109716\n",
      "BILL_AMT1                  0.00889782\n",
      "AvgPay_to_LIMIT_BAL        0.00731515\n",
      "BILL_AMT2                  0.00723592\n",
      "PAY_AMT5                   0.00707999\n",
      "BILL_AMT3                  0.00517733\n",
      "BILL_AMT5                  0.00496441\n",
      "BILL_AMT4                  0.00391474\n",
      "BILL_AMT6                  0.00346256\n",
      "AGE                        0.00192295\n",
      "EDUCATION_INP_4            0.00074076\n",
      "SEX_2                      0.000347426\n",
      "MARRIAGE_INP_2             0.000269609\n",
      "EDUCATION_INP_3            0.000175999\n",
      "EDUCATION_INP_2            0.000145927\n",
      "MARRIAGE_INP_3             6.08715e-05\n"
     ]
    }
   ],
   "source": [
    "# View a list of the features and their importance scores\n",
    "# Source:\n",
    "# http://www.markhneedham.com/blog/2017/06/16/scikit-learn-random-forests-feature-importance/\n",
    "# https://chrisalbon.com/machine_learning/trees_and_forests/random_forest_classifier_example/\n",
    "\n",
    "from tabulate import tabulate\n",
    "headers = ['name', 'score']\n",
    "values = sorted(zip(class_t.columns, model_rf.feature_importances_), key=lambda x: x[1] * -1)\n",
    "rf_feature_importance = tabulate(values, headers, tablefmt=\"plain\")\n",
    "print(rf_feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of l1 metrics is 52.6333333333 %\n",
      "\n",
      "Accuracy of l2 metrics is 53.6 %\n",
      "\n",
      "Accuracy of cosine metrics is 54.4666666667 %\n",
      "\n",
      "The best measurment of distance is cosine\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/neighbors/nearest_centroid.py:140: UserWarning: Averaging for metrics other than euclidean and manhattan not supported. The average is set to be the mean.\n",
      "  warnings.warn(\"Averaging for metrics other than \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "\n",
    "for d in ['l1','l2','cosine']:\n",
    "    clf = NearestCentroid(metric=d)\n",
    "    clf.fit(X_c_train, y_c_train)\n",
    "    KNNyhat2 = clf.predict(X_c_test)\n",
    "    KNNacc2 = mt.accuracy_score(y_c_test,KNNyhat2)\n",
    "    print('\\nAccuracy of', d, 'metrics is', KNNacc2 * 100, '%')   \n",
    "\n",
    "print('\\nThe best measurment of distance is cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 1 neighbors is 69.9333333333 %\n",
      "Accuracy of 2 neighbors is 76.5333333333 %\n",
      "Accuracy of 4 neighbors is 77.65 %\n",
      "Accuracy of 8 neighbors is 78.0833333333 %\n",
      "\n",
      "The best accuracy is 0.780833 with 8 neighbor(s)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "max_accs3 = 0\n",
    "max_k3 = 0\n",
    "\n",
    "#the below KNN model has been adjusted to have 8 nearest neighbors and its using the distance metric 'cosine' to measure\n",
    "for k in range(1,10):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='cosine')\n",
    "    clf.fit(X_c_train, y_c_train)\n",
    "    KNNyhat3 = clf.predict(X_c_test)\n",
    "    KNNacc3 = mt.accuracy_score(y_c_test,KNNyhat3)\n",
    "    if max(max_accs3, KNNacc3) == KNNacc3:\n",
    "        max_accs3 = KNNacc3\n",
    "        max_k3 = k\n",
    "        print('Accuracy of', k, 'neighbors is', KNNacc3 * 100, '%')\n",
    "\n",
    "print('\\nThe best accuracy is %f with %d neighbor(s)'%(max_accs3,max_k3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 8 neighbors is 78.0833333333\n",
      "confusion matrix\n",
      " [[3873  800]\n",
      " [ 548  779]]\n",
      "\n",
      " *** CLASSIFICATION REPORT ****\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.97      0.87      4673\n",
      "          1       0.52      0.11      0.18      1327\n",
      "\n",
      "avg / total       0.73      0.78      0.72      6000\n",
      "\n",
      "recall is: 0.598342125094\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.html import widgets \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "#max_accs = 0\n",
    "#max_k = 0\n",
    "\n",
    "#the below KNN model has been adjusted to have 8 nearest neighbors and its using the distance metric 'cosine' to measure\n",
    "#for k in range():\n",
    "clf = KNeighborsClassifier(n_neighbors=8, weights='uniform', metric='cosine')\n",
    "clf.fit(X_c_train, y_c_train)\n",
    "KNNyhat = clf.predict(X_c_test)\n",
    "KNNacc = mt.accuracy_score(y_c_test,KNNyhat)\n",
    "#if max(max_accs, acc) == acc:\n",
    " #   max_accs = acc\n",
    "  #  max_k = k\n",
    "print('Accuracy of 8 neighbors is', KNNacc * 100)\n",
    "\n",
    "# now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "#print('\\nThe best accuracy is %f with %d neighbor(s)'%(max_accs,max_k))\n",
    "#acc = mt.accuracy_score(y_c_test,y_hat)\n",
    "#conf = mt.confusion_matrix(y_c_test,y_hat)\n",
    "#print(\"====Iteration\",iter_num,\" ====\")\n",
    "#print(\"accuracy\", acc )\n",
    "print(\"confusion matrix\\n\",conf)\n",
    "\n",
    "print(\"\\n *** CLASSIFICATION REPORT ****\")\n",
    "#### CLASSIFICATION REPORT\n",
    "ClassReportKNN = mt.classification_report(y_c_test,KNNyhat)\n",
    "print(ClassReportKNN)\n",
    "\n",
    "KNNrecall2 = mt.recall_score(y_c_test,KNNyhat2)\n",
    "print('recall is:',KNNrecall2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the KNN classification we used the classification report to measure how well the model performed. We found the best KNN model used the cosine distance metric and used 8 nearest neighbors. It had an average precision of .73 which means 73% of the time it is correctly classifying the observation correctly. This model had an average recall of .78 which means it has the ability to classify all of the positives samples at 78%. Finally it had an F1 score or .72 which shows this is a relatively strong model because the F1 score weighs all data points equally. Since by chance there is a 50% chance of classifying a subject correctly, this model would be useful to help better correctly classify someone to see if they will default or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:   31.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedShuffleSplit(n_splits=10, random_state=1, test_size=0.2,\n",
       "            train_size=0.8),\n",
       "       error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ('l1', 'l2'), 'C': [1], 'class_weight': ['balanced', None]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run logistic regression and vary some parameters\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "from time import time\n",
    "\n",
    "\n",
    "#lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) # get object\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "#class_weight='balanced'\n",
    "\n",
    "parameters = {'penalty':('l1','l2'),'C':[1],'class_weight': ['balanced',None]}\n",
    "\n",
    "#parameters = {'normalize':(True,False), 'fit_intercept':(True,False)}\n",
    "#'kernel':('linear', 'rbf')\n",
    "\n",
    "#\n",
    "'''\n",
    "parameters = { 'penalty':['l2']\n",
    "              ,'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "              ,'class_weight': ['balanced',None]\n",
    "              ,'solver': ['lbfgs']\n",
    "              ,'max_iter':[100,500]\n",
    "             }\n",
    "'''\n",
    "\n",
    "\n",
    "#'accuracy'\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "LogregGridSearch = GridSearchCV(estimator=lr_clf\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_object # KFolds = 10\n",
    "                   , scoring='recall')\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "#regGridSearch.fit(X_r, y_r)\n",
    "LogregGridSearch.fit(X_c, y_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the parameterization of the best estimator\n",
    "LogregGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WE RUN A LOGISTIC REGRESSION WITH THE BEST CONFIGURATION\n",
    "\n",
    "#We set to the best regression configuration obtained\n",
    "LogregEstimator = LogregGridSearch.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "LogregEstimator.fit(X_c_train,y_c_train)  # train object\n",
    "\n",
    "y_c_hat = LogregEstimator.predict(X_c_test) # get test set precition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EvaluateClassifierEstimator(classifierEstimator, X, y, cv):\n",
    "   \n",
    "    #Perform cross validation - it had X_highSchools and Y, I am going to change it to X and y\n",
    "    scores = cross_validate(classifierEstimator, X, y, scoring=['accuracy','precision','recall']\n",
    "                            , cv=cv, return_train_score=True)\n",
    "\n",
    "    Accavg = scores['test_accuracy'].mean()\n",
    "    Preavg = scores['test_precision'].mean()\n",
    "    Recavg = scores['test_recall'].mean()\n",
    "\n",
    "    print_str = \"The average accuracy for all cv folds is: \\t\\t\\t {Accavg:.5}\"\n",
    "    print_str2 = \"The average precision for all cv folds is: \\t\\t\\t {Preavg:.5}\"\n",
    "    print_str3 = \"The average recall for all cv folds is: \\t\\t\\t {Recavg:.5}\"\n",
    "\n",
    "    print(print_str.format(Accavg=Accavg))\n",
    "    print(print_str2.format(Preavg=Preavg))\n",
    "    print(print_str3.format(Recavg=Recavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['Accuracy'] = scores['test_accuracy']\n",
    "    scoresResults['Precision'] = scores['test_precision']\n",
    "    scoresResults['Recall'] = scores['test_recall']\n",
    "\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average accuracy for all cv folds is: \t\t\t 0.59183\n",
      "The average precision for all cv folds is: \t\t\t 0.31855\n",
      "The average recall for all cv folds is: \t\t\t 0.69902\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.541500</td>\n",
       "      <td>0.287716</td>\n",
       "      <td>0.727204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.297667</td>\n",
       "      <td>0.721176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.733667</td>\n",
       "      <td>0.430262</td>\n",
       "      <td>0.629992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.568500</td>\n",
       "      <td>0.299937</td>\n",
       "      <td>0.712886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.557500</td>\n",
       "      <td>0.289206</td>\n",
       "      <td>0.686511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.567833</td>\n",
       "      <td>0.300441</td>\n",
       "      <td>0.718161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.562000</td>\n",
       "      <td>0.292239</td>\n",
       "      <td>0.689525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.571167</td>\n",
       "      <td>0.305798</td>\n",
       "      <td>0.739261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.560333</td>\n",
       "      <td>0.298741</td>\n",
       "      <td>0.733233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.693833</td>\n",
       "      <td>0.383455</td>\n",
       "      <td>0.632253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Precision    Recall\n",
       "0  0.541500   0.287716  0.727204\n",
       "1  0.562000   0.297667  0.721176\n",
       "2  0.733667   0.430262  0.629992\n",
       "3  0.568500   0.299937  0.712886\n",
       "4  0.557500   0.289206  0.686511\n",
       "5  0.567833   0.300441  0.718161\n",
       "6  0.562000   0.292239  0.689525\n",
       "7  0.571167   0.305798  0.739261\n",
       "8  0.560333   0.298741  0.733233\n",
       "9  0.693833   0.383455  0.632253"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We set to the best regression configuration obtained\n",
    "LogregEstimator = LogregGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "#EvaluateRegressionEstimator(regEstimator, X_r, y_r, cv_reg)\n",
    "EvaluateClassifierEstimator(LogregEstimator, X_c, y_c, cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance for Logistic Regression\n",
    "\n",
    ">In this section, we will identify the most important factors based upon the magnitude of the coefficient in the logistic regression. For that purpose, we will standardize the variables to eliminate the fact of having variables in different scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BILL_AMT1 has weight of -0.225892983009\n",
      "LIMIT_BAL has weight of -0.192429506347\n",
      "PAY_AMT1 has weight of -0.175839653363\n",
      "EDUCATION_INP_4 has weight of -0.113019170256\n",
      "PAY_AMT2 has weight of -0.0868317356707\n",
      "Avg_PAY has weight of -0.0865954171933\n",
      "SEX_2 has weight of -0.0814209355989\n",
      "MARRIAGE_INP_2 has weight of -0.0806895465512\n",
      "BILL_AMT6 has weight of -0.0482536525941\n",
      "AvgBill_to_LIMIT_BAL has weight of -0.0413148315216\n",
      "BILL_AMT4 has weight of -0.0368892936969\n",
      "PAY_AMT3 has weight of -0.0217247819271\n",
      "BILL_AMT5 has weight of -0.0164073591427\n",
      "PAY_AMT5 has weight of -0.0101755750332\n",
      "EDUCATION_INP_3 has weight of -0.00741713257292\n",
      "PAY_AMT6 has weight of -0.00103212183776\n",
      "MARRIAGE_INP_3 has weight of 0.000109044551732\n",
      "PAY_AMT4 has weight of 0.00292395390268\n",
      "Avg_BILL has weight of 0.00705901818323\n",
      "AvgPay_to_LIMIT_BAL has weight of 0.00789023365001\n",
      "EDUCATION_INP_2 has weight of 0.00842416688512\n",
      "AGE has weight of 0.0532173664096\n",
      "PAY_4_range_delay > 1 has weight of 0.0772421649601\n",
      "PAY_5_range_delay > 1 has weight of 0.0798785798136\n",
      "PAY_2_range_delay > 1 has weight of 0.0835643088118\n",
      "BILL_AMT3 has weight of 0.0890662022954\n",
      "PAY_6_range_delay > 1 has weight of 0.0923794524616\n",
      "PAY_3_range_delay > 1 has weight of 0.12609772651\n",
      "PAY_1_range_delay 1 month  has weight of 0.255480599719\n",
      "BILL_AMT2 has weight of 0.273821741313\n",
      "PAY_1_range_delay > 1 has weight of 0.621001749367\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# we want to normalize the features based upon the mean and standard deviation of each column. \n",
    "# However, we do not want to accidentally use the testing data to find out the mean and std (this would be snooping)\n",
    "# to Make things easier, let's start by just using whatever was last stored in the variables:\n",
    "##    X_train , y_train , X_test, y_test (they were set in a for loop above)\n",
    "\n",
    "# scale attributes by the training set\n",
    "#scl_obj = StandardScaler()\n",
    "#scl_obj.fit(X_c_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "#X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "#X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "#lr_clf = LogisticRegression(penalty='l2', C=1, class_weight='balanced') # get object, the 'C' value is less (can you guess why??)\n",
    "\n",
    "\n",
    "\n",
    "LogregEstimator.fit(X_c_train_scaled, y_c_train)\n",
    "\n",
    "#lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_c_hat = LogregEstimator.predict(X_c_test_scaled) # get test set precitions\n",
    "\n",
    "#recall = mt.recall_score(y_c_test,y_c_hat)\n",
    "#conf = mt.confusion_matrix(y_c_test,y_c_hat)\n",
    "#print('Recall:', recall )\n",
    "#print(conf)\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(LogregEstimator.coef_.T,class_t.columns) # combine attributes\n",
    "zip_vars = sorted(zip_vars)\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAGDCAYAAADDFBAFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfl+0NX4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11026fc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now let's make a pandas Series with the names and values, and plot them\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#it had df.columns\n",
    "weights = pd.Series(LogregEstimator.coef_[0],index=class_t.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The most important variables to predict the default according to the logistic regression are:\n",
    "\n",
    "\n",
    ">a) The repayment status of the most recent month (dummy variables: Pay_1_range_delay 1 month, Pay_1_rande delay < 1)\n",
    "\n",
    ">b) The amount of bill statement of the most recent month (BILL_AMT1)\n",
    "\n",
    ">c) Limit Balance (LIMIT_BAL)\n",
    "\n",
    ">d) The amount paid in the most recent month (PAY_AMT1)\n",
    "\n",
    ">Among the socio-economic variables (Sex, Education, Marriage, and Age), the Education is the most relevant, followed by Marriage, sex, and age.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Regression-Task\"></a>Regression Task\n",
    "\n",
    ">[20 points] Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression task Objective\n",
    "> The purpose of the regression task will be to predict the ratio: \"Ratio of average bill amount to credit limit balance\".  That will give the bank the ability to target customers with very low usage of their credit and offer them additional products and conversely identify customers that are close to use total balance limit to monitor theri behavior and allocate capital for potendial defaults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We first build the code to measure the performance metrics for the regression task. The code is extracted from:\n",
    "* http://localhost:8888/notebooks/Documents/Master%20Data%20Science/DataMining/EducationNC_Project/Graduation%20Rates%20v2%20(1).ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SETTING UP THE PERFORMANCE METRICS\n",
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual != 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation\n",
    "** All regression models are evaluated using the regression model evaluation function below: ** \n",
    "* The following regression evaluation function uses the cross validation object and the custom scorers in the two cells above in combination with sklearn.model_selection's cross_validate function to perform cross validation for regression estimators.\n",
    "* The cross validation object above uses a random seed to ensure that all regression estimators are tested on the same randomly selected records for each cross validation fold.\n",
    "* Custom scorers are created using the three chosen mean error scores and passed into cross_validate(), so all three scores are calculated using a single call to cross_validate().\n",
    "* All of this functionality is wrapped within the custom EvaluateRegressionEstimator() function below so multiple regression models may be tested using the same test / train CV data and evaluation scores producing a consistent output for each model without the need to re-write the same code over and over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Regression Model\n",
    "\n",
    "**Linear Regression is used to create a baseline model.  Since linear regression may predict response variable values outside the range of the training data's response variable, we create a linear regression estimator with minority percentage predictions clipped 0% and 100%. For details see:**\n",
    "* http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator \n",
    "* https://github.com/scikit-learn/scikit-learn/issues/6950\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/template.py\n",
    "* https://stackoverflow.com/questions/44234682/how-to-use-sklearn-when-target-variable-is-a-proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make new estimator compatible for use with GridSearchCV() and cross_validate()\n",
    "# -  Cap predict function for LinearRegression between 0 and 100\n",
    "# -  See: Roll your own estimator links above for details. \n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class CappedLinearRegression(LinearRegression):\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.clip(super(CappedLinearRegression, self).predict(X), 0, 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Grid Search\n",
    "** Here we perform a grid search testing 40 models to find the best parameters for our Linear Regression model based on Mean Absolute Error.  See more on parameter tuning with grid search here:**\n",
    "* http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=10, random_state=1, test_size=0.2, train_size=0.8),\n",
       "       error_score='raise',\n",
       "       estimator=CappedLinearRegression(copy_X=True, fit_intercept=True, n_jobs=1,\n",
       "            normalize=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'normalize': (True, False), 'fit_intercept': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "linreg = CappedLinearRegression()\n",
    "parameters = {'normalize':(True,False), 'fit_intercept':(True,False)}\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "#regGridSearch.fit(X_r, y_r)\n",
    "regGridSearch.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CappedLinearRegression(copy_X=True, fit_intercept=False, n_jobs=1,\n",
       "            normalize=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the parameterization of the best estimator\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Baseline Regression Model - Cross Validation\n",
    "**Perform tenfold cross validation using the grid search \"best\" parameters and our Capped Linear Regression estimator**\n",
    "* 10-fold cross-validation using the parameters for the top performing model \n",
    "* CAP predictions between 0 and 100% \n",
    "* Evaluate cross-validation results using MAE, MAPE, and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 0.27795\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t 440.93\n",
      "The average RMSE for all cv folds is: \t\t\t 0.33199\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/Jostein/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.280974</td>\n",
       "      <td>1626.461378</td>\n",
       "      <td>0.336603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.275041</td>\n",
       "      <td>-776.651246</td>\n",
       "      <td>0.324731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276983</td>\n",
       "      <td>-1353.791854</td>\n",
       "      <td>0.329080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276121</td>\n",
       "      <td>1642.440461</td>\n",
       "      <td>0.327817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277215</td>\n",
       "      <td>1142.015559</td>\n",
       "      <td>0.328727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.275749</td>\n",
       "      <td>20.446140</td>\n",
       "      <td>0.328822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.280816</td>\n",
       "      <td>-498.179496</td>\n",
       "      <td>0.334812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.279137</td>\n",
       "      <td>363.747926</td>\n",
       "      <td>0.340738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.277709</td>\n",
       "      <td>926.656446</td>\n",
       "      <td>0.329714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.279714</td>\n",
       "      <td>1316.172201</td>\n",
       "      <td>0.338904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE         MAPE      RMSE\n",
       "0  0.280974  1626.461378  0.336603\n",
       "1  0.275041  -776.651246  0.324731\n",
       "2  0.276983 -1353.791854  0.329080\n",
       "3  0.276121  1642.440461  0.327817\n",
       "4  0.277215  1142.015559  0.328727\n",
       "5  0.275749    20.446140  0.328822\n",
       "6  0.280816  -498.179496  0.334812\n",
       "7  0.279137   363.747926  0.340738\n",
       "8  0.277709   926.656446  0.329714\n",
       "9  0.279714  1316.172201  0.338904"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "#EvaluateRegressionEstimator(regEstimator, X_r, y_r, cv_reg)\n",
    "EvaluateRegressionEstimator(regEstimator, X_r, y_r, cv_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEaCAYAAAAfVJzKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11133d7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the distribution is 0.2778487198600677\n",
      "The median of the distribution is 0.27788054200761864\n"
     ]
    }
   ],
   "source": [
    "#Build a sampling distribution of the MAE via bootstrap\n",
    "# - 1000 random samples with replacement  \n",
    "# - Look at dist plot for the 1000 MAE's  \n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "\n",
    "# train on all of the data\n",
    "regEstimator.fit(X_r, y_r)\n",
    "\n",
    "maeList = []  # an empty list for MAE\n",
    "sampleCt = len(y_r) # large same equal to validation set size, but w/ replacement!\n",
    "y_r_hatMin = 0\n",
    "y_r_hatMax = 0\n",
    "\n",
    "for i in range(1000): # 1,000 samples\n",
    "    X_r_samp, y_r_samp = resample(X_r, y_r, replace=True, n_samples=sampleCt)\n",
    "    y_r_hat = regEstimator.predict(X_r_samp)\n",
    "    mae = mean_absolute_error(y_r_samp, y_r_hat)\n",
    "    maeList.append(mae)\n",
    "    y_r_hatMin = np.minimum(y_r_hat.min(), y_r_hatMin)\n",
    "    y_r_hatMax = np.maximum(y_r_hat.max(), y_r_hatMax)\n",
    "\n",
    "#Print distributions for MAE\n",
    "sns.distplot(maeList).set_title(\"Mean Absolute Error\\nSampling Distribution Plot\")  \n",
    "plt.show()\n",
    "\n",
    "print(\"The mean of the distribution is {mean}\".format(mean=np.mean(maeList)))\n",
    "print(\"The median of the distribution is {median}\".format(median=np.median(maeList)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression Feature Importance - Capped Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale dataset converting to standard normally distributed data \n",
    "# (e.g. Gaussian with 0 mean and unit variance).\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Fit to data for scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_r)\n",
    "\n",
    "#Transform training data to z-scores\n",
    "#This makes our model's coefficients take on the same scale for accurate feature importance analisys \n",
    "X_r_scl = scaler.transform(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CappedLinearRegression(copy_X=True, fit_intercept=False, n_jobs=1,\n",
       "            normalize=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#linreg_fi = linreg_clf.best_estimator_\n",
    "regEstimator_fi = regGridSearch.best_estimator_\n",
    "\n",
    "#Fit the model using all of our scaled data\n",
    "regEstimator_fi.fit(X_r_scl, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAAGhCAYAAAAqdBC7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHZIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11215b898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the model's coefficient weights and feature names into a dataframe sorted by weights\n",
    "weights = regEstimator_fi.coef_\n",
    "#### WARNING HERE\n",
    "feature_names = reg_t.columns\n",
    "linreg_ft_imp_df = pd.DataFrame({'feature_names':feature_names, 'weights':weights, 'absolute_weights': np.abs(weights)})\n",
    "linreg_ft_imp_df.sort_values(by='absolute_weights', inplace=True, ascending=False )\n",
    "\n",
    "#Plot the model's feature importances\n",
    "# REFERENCE:  Eric Larson, https://github.com/eclarson/DataMiningNotebooks\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "wt_plt_df = linreg_ft_imp_df.head(10)\n",
    "\n",
    "weights = pd.Series(wt_plt_df['weights'].values,index=wt_plt_df['feature_names'])\n",
    "ax = weights.plot(kind='bar')\n",
    "\n",
    "ax.set_title(\"Top Feature Correlations\")\n",
    "ax.set_ylabel(\"Coefficient Magnitude\\n(z-score)\")\n",
    "ax.set_xlabel(\"Feature Names\")\n",
    "plt.savefig(\"top_feature_correlations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Lasso Regression\n",
    "**Perform regression using Linear Model trained with L1 prior as regularizer (aka the Lasso)**\n",
    "\n",
    "Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-24:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-18:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-17:\n",
      "Process ForkPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 360, in get\n",
      "    racquire()\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/pool.py\", line 362, in get\n",
      "    return recv()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 250, in recv\n",
      "    buf = self._recv_bytes()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/Jostein/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4f752e378893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#Perform hyperparameter search to find the best combination of parameters for our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mregGridSearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lassoreg = Lasso(fit_intercept=True, normalize=True,copy_X=True\n",
    "          , max_iter=10000, precompute=True, tol=0.0001, random_state=0)\n",
    "\n",
    "#Test parameters \n",
    "alpha = [0.001, 0.1, 1, 10, 20]\n",
    "selection = ['cyclic','random']\n",
    "warm_start = [True, False]\n",
    "parameters = {'alpha': alpha, 'selection': selection, 'warm_start': warm_start}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=lassoreg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X_r, y_r, cv_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a sampling distribution of the MAE via bootstrap\n",
    "# - 1000 random samples with replacement  \n",
    "# - Look at dist plot for the 1000 MAE's  \n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "\n",
    "# train on all of the data\n",
    "regEstimator.fit(X_r, y_r)\n",
    "\n",
    "maeList = []  # an empty list for MAE\n",
    "sampleCt = len(y_r) # large same equal to validation set size, but w/ replacement!\n",
    "y_r_hatMin = 0\n",
    "y_r_hatMax = 0\n",
    "\n",
    "for i in range(1000): # 1,000 samples\n",
    "    X_r_samp, y_r_samp = resample(X_r, y_r, replace=True, n_samples=sampleCt)\n",
    "    y_r_hat = regEstimator.predict(X_r_samp)\n",
    "    mae = mean_absolute_error(y_r_samp, y_r_hat)\n",
    "    maeList.append(mae)\n",
    "    y_r_hatMin = np.minimum(y_r_hat.min(), y_r_hatMin)\n",
    "    y_r_hatMax = np.maximum(y_r_hat.max(), y_r_hatMax)\n",
    "\n",
    "#Print distributions for MAE\n",
    "sns.distplot(maeList).set_title(\"Mean Absolute Error\\nSampling Distribution Plot\")  \n",
    "plt.show()\n",
    "\n",
    "print(\"The mean of the distribution is {mean}\".format(mean=np.mean(maeList)))\n",
    "print(\"The median of the distribution is {median}\".format(median=np.median(maeList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale dataset converting to standard normally distributed data \n",
    "# (e.g. Gaussian with 0 mean and unit variance).\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Fit to data for scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_r)\n",
    "\n",
    "#Transform training data to z-scores\n",
    "#This makes our model's coefficients take on the same scale for accurate feature importance analysis \n",
    "X_r_scl = scaler.transform(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linreg_fi = linreg_clf.best_estimator_\n",
    "regEstimator_fi = regGridSearch.best_estimator_\n",
    "\n",
    "#Fit the model using all of our scaled data\n",
    "regEstimator_fi.fit(X_r_scl, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we predict Average Bill amount to card Limit Balance ratios greater than 100%?\n",
    "regEstimator = Lasso(alpha=0.001, copy_X=True, fit_intercept=True, max_iter=10000,\n",
    "   normalize=True, positive=False, precompute=True, random_state=0,\n",
    "   selection='cyclic', tol=0.0001, warm_start=True)\n",
    "\n",
    "regEstimator.fit(X_r, y_r)\n",
    "yhat = regEstimator.predict(X_r)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Ridge Regression\n",
    "**Perform regression using Linear least squares with l2 regularization**\n",
    "\n",
    "Documentation: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a regression object and perform a grid search to find the best parameters\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridgereg = Ridge(fit_intercept=True, normalize=True,copy_X=True\n",
    "          , max_iter=1000, tol=0.0001, random_state=0)\n",
    "\n",
    "#Test parameters \n",
    "alpha = [0.001, 0.1, 1, 5, 10, 20]\n",
    "solver = [ 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga']\n",
    "parameters = {'alpha': alpha, 'solver': solver}\n",
    "\n",
    "#Create a grid search object using the parameters above\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=ridgereg\n",
    "                   , n_jobs=8 # jobs to run in parallel\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the best estimator parameters\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a regression estimator with best parameters for cross validation\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics.\n",
    "EvaluateRegressionEstimator(regEstimator, X_r, y_r, cv_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a sampling distribution of the MAE via bootstrap\n",
    "# - 1000 random samples with replacement  \n",
    "# - Look at dist plot for the 1000 MAE's  \n",
    "from sklearn.utils import resample\n",
    "import seaborn as sns\n",
    "\n",
    "# train on all of the data\n",
    "regEstimator.fit(X_r, y_r)\n",
    "\n",
    "maeList = []  # an empty list for MAE\n",
    "sampleCt = len(y_r) # large same equal to validation set size, but w/ replacement!\n",
    "y_r_hatMin = 0\n",
    "y_r_hatMax = 0\n",
    "\n",
    "for i in range(1000): # 1,000 samples\n",
    "    X_r_samp, y_r_samp = resample(X_r, y_r, replace=True, n_samples=sampleCt)\n",
    "    y_r_hat = regEstimator.predict(X_r_samp)\n",
    "    mae = mean_absolute_error(y_r_samp, y_r_hat)\n",
    "    maeList.append(mae)\n",
    "    y_r_hatMin = np.minimum(y_r_hat.min(), y_r_hatMin)\n",
    "    y_r_hatMax = np.maximum(y_r_hat.max(), y_r_hatMax)\n",
    "\n",
    "#Print distributions for MAE\n",
    "sns.distplot(maeList).set_title(\"Mean Absolute Error\\nSampling Distribution Plot\")  \n",
    "plt.show()\n",
    "\n",
    "print(\"The mean of the distribution is {mean}\".format(mean=np.mean(maeList)))\n",
    "print(\"The median of the distribution is {median}\".format(median=np.median(maeList)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale dataset converting to standard normally distributed data \n",
    "# (e.g. Gaussian with 0 mean and unit variance).\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Fit to data for scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_r)\n",
    "\n",
    "#Transform training data to z-scores\n",
    "#This makes our model's coefficients take on the same scale for accurate feature importance analysis \n",
    "X_r_scl = scaler.transform(X_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linreg_fi = linreg_clf.best_estimator_\n",
    "regEstimator_fi = regGridSearch.best_estimator_\n",
    "\n",
    "#Fit the model using all of our scaled data\n",
    "regEstimator_fi.fit(X_r_scl, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the model's coefficient weights and feature names into a dataframe sorted by weights\n",
    "weights = regEstimator_fi.coef_\n",
    "#### WARNING HERE\n",
    "feature_names = reg_t.columns\n",
    "ridgereg_ft_imp_df = pd.DataFrame({'feature_names':feature_names, 'weights':weights, 'absolute_weights': np.abs(weights)})\n",
    "ridgereg_ft_imp_df.sort_values(by='absolute_weights', inplace=True, ascending=False )\n",
    "\n",
    "#Plot the model's feature importances\n",
    "# REFERENCE:  Eric Larson, https://github.com/eclarson/DataMiningNotebooks\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "wt_plt_df = ridgereg_ft_imp_df.head(10)\n",
    "\n",
    "weights = pd.Series(wt_plt_df['weights'].values,index=wt_plt_df['feature_names'])\n",
    "ax = weights.plot(kind='bar')\n",
    "\n",
    "ax.set_title(\"Top Feature Correlations\")\n",
    "ax.set_ylabel(\"Coefficient Magnitude\\n(z-score)\")\n",
    "ax.set_xlabel(\"Feature Names\")\n",
    "plt.savefig(\"top_feature_corr\")\n",
    "plt.show()\n",
    "\n",
    "#ridgereg_ft_imp_df.info()\n",
    "#ridgereg_ft_imp_df.head(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we predict Average Bill amount to card Limit Balance ratios greater than 100%?\n",
    "regEstimator = Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=True, random_state=0, solver='saga', tol=0.0001)\n",
    "\n",
    "regEstimator.fit(X_r, y_r)\n",
    "yhat = regEstimator.predict(X_r)\n",
    "print(\"Yhat Max: \", yhat.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Methods-of-Evaluation\"></a>Methods of Evaluation Results\n",
    "\n",
    "> [10 points] Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Results for Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using the best configuration for each of the 3 algorithms explored (Random forest, KNN neighbors, and Logistic Regression), we will run 10 CV folds and calculate the recall to get a general sense of the distribution of the recall metric for each of the algorithms. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CREATE 10 FOLDS for the LOGISTIC REGRESSION with the corresponding recalls\n",
    "\n",
    "### WE RUN A LOGISTIC REGRESSION WITH THE BEST CONFIGURATION\n",
    "\n",
    "#We set to the best regression configuration obtained\n",
    "LogregEstimator = LogregGridSearch.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "#clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores_M1 = cross_validate(LogregEstimator, X_c, y_c, scoring=scoring,\n",
    "                         cv=10, return_train_score=False)\n",
    "sorted(scores_M1.keys())\n",
    "#['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n",
    "scores_M1['test_recall_macro']                       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CREATE 10 FOLDS for the KNN NEIGHBORS with the corresponding recalls\n",
    "\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=8, weights='uniform', metric='cosine')\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "\n",
    "scores_M2 = cross_validate(clf_KNN, X_c, y_c, scoring=scoring,\n",
    "                         cv=10, return_train_score=False)\n",
    "\n",
    "\n",
    "scores_M2['test_recall_macro'] \n",
    "\n",
    "print(scores_M2['test_recall_macro'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CREATE 10 FOLDS for the random forest with the corresponding recalls\n",
    "\n",
    "clf_rfor = RandomForestClassifier(max_depth=5, min_samples_split=2, random_state=0, class_weight='balanced',\n",
    "                             max_features='auto', n_estimators=500, bootstrap=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "\n",
    "scores_M3 = cross_validate(clf_rfor, X_c, y_c, scoring=scoring,\n",
    "                         cv=10, return_train_score=False)\n",
    "\n",
    "\n",
    "scores_M3['test_recall_macro'] \n",
    "\n",
    "print(scores_M3['test_recall_macro'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create a DATA FRAME to record the recall and then make the BOX plot to visualize the recall metric\n",
    "\n",
    "lrg_recall=scores_M1['test_recall_macro']\n",
    "print(lrg_recall)\n",
    "print(type(lrg_recall))\n",
    "\n",
    "\n",
    "knn_recall=scores_M2['test_recall_macro']\n",
    "\n",
    "rfor_recall=scores_M3['test_recall_macro']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZATION OF THE PERFORMANCE METRICS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "lrg_recall=scores_M1['test_recall_macro']\n",
    "knn_recall=scores_M2['test_recall_macro']\n",
    "rfor_recall=scores_M3['test_recall_macro']\n",
    "df_a = pd.DataFrame({'logistic_recall':lrg_recall, 'knn_recall':knn_recall, 'random_forest_recall':rfor_recall})\n",
    "#df_a.plot('x', 'y', kind='scatter')\n",
    "df_a.head()\n",
    "print(type(df_a))\n",
    "\n",
    "\n",
    "#boxplot\n",
    "fig, ax = plt.subplots()\n",
    "box = df_a.boxplot(ax=ax, sym='',return_type='dict') \n",
    "ax.margins(y=0.05)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> After running 10 CV scenarios for the best model under the 3 different methods (KNN neighbors, logistic regression, and Random forest), the random forest yields the highest recall. Therefore, the best classification model is the random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Advantages-of-each-model\"></a>Advantages of each model\n",
    ">[10 points] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques — be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the course\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### CREATE 10 FOLDS for the LOGISTIC REGRESSION with the corresponding acuracies\n",
    "\n",
    "### WE RUN A LOGISTIC REGRESSION WITH THE BEST CONFIGURATION\n",
    "\n",
    "#We set to the best regression configuration obtained\n",
    "LogregEstimator = LogregGridSearch.best_estimator_\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "#clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores_M1 = cross_validate(LogregEstimator, X_c, y_c, scoring=scoring,\n",
    "                         cv=10, return_train_score=False)\n",
    "sorted(scores_M1.keys())\n",
    "#['fit_time', 'score_time', 'test_precision_macro', 'test_recall_macro']\n",
    "scores_M1['test_recall_macro']                       \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### CREATE 10 FOLDS for the KNN NEIGHBORS with the corresponding acuracies\n",
    "\n",
    "clf_KNN = KNeighborsClassifier(n_neighbors=8, weights='uniform', metric='cosine')\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "\n",
    "scores_M2 = cross_validate(clf_KNN, X_c, y_c, scoring=scoring,\n",
    "                         cv=10, return_train_score=False)\n",
    "\n",
    "\n",
    "scores_M2['test_recall_macro'] \n",
    "\n",
    "print(scores_M2['test_recall_macro'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####EXECUTING THE STATISTICAL COMPARISON\n",
    "\n",
    "print(scores_M1['test_recall_macro'])\n",
    "\n",
    "print(scores_M2['test_recall_macro'])\n",
    "\n",
    "t = 2.26 / np.sqrt(10)\n",
    "\n",
    "e = (1-scores_M1['test_recall_macro'])-(1-scores_M2['test_recall_macro'])\n",
    "\n",
    "print(e)\n",
    "\n",
    "stdtot = np.std(e)\n",
    "\n",
    "dbar = np.mean(e)\n",
    "print ('Range of:', dbar-t*stdtot,dbar+t*stdtot )\n",
    "print (np.mean(scores_M1['test_recall_macro']), np.mean(scores_M2['test_recall_macro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The CI of 95% does not contain the value of ZERO, there is evidence to reject the fact that they are equal. Therefore, we can compare the metrics of performance between the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Regarding the regression models, the capped multiple regression model has the lowest mean absolute error mean, which has an MAE value that is nearly identical to the ridge regression model.In regards to the classification models, KNN and Random Forest, the Random Forest model performed better based the accuracy, recall and F1 measurements. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Relevant-Attributes\"></a>Relevant Attributes\n",
    ">[10 points] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN works best when there is low dimensionality, meaning not using hundreds of features, which could help explain why it performed so poorly on this data set.  Furthermore, normalizing your data so that each feature is on the same scale will create a better model. With this in mind, there are not features that are less or more important in a KNN model that we can find after the model has been run. The process of selecting features should be perfmored before the model is created. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Top Feature Correlations](top_feature_correlations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Deployment\"></a>Deployment\n",
    ">[5 points] How useful is your model for interested parties (i.e., the companies or organizations\n",
    "that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all add your own part. we can clean up after all ideas are put down. \n",
    "\n",
    "KNN- this could be used to classify someone before they are a customer whether they will default or not. With this info, targeted products for the consumer or marketing campaigns could be deployed to gain more users and also protect against user that are likely to default. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Exceptional-Work\"></a>Exceptional Work\n",
    "> [10 points] You have free reign to provide additional analyses\n",
    "> One idea: grid search parameters in a parallelized fashion and visualize the\n",
    "performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our exceptional work, we created additional variables as well as perfomed a grid search testing 40 models to find the best parameters for our Linear Regression model based on MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <a name=\"References\"></a>References\n",
    "\n",
    "* https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "* https://github.com/jakemdrew/EducationDataNC/blob/master/Graduation%20Rates%20v2.ipynb\n",
    "* http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "* https://stackoverflow.com/questions/29438265/stratified-train-test-split-in-scikit-learn\n",
    "* http://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "* https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html\n",
    "* https://machinelearningmastery.com/k-nearest-neighbors-for-machine-learning/\n",
    "* https://en.wikipedia.org/wiki/Mean_absolute_percentage_error\n",
    "* http://scikit-learn.org/stable/modules/cross_validation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
