{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "## MSDS 7349 - Section 401\n",
    "## Project 2\n",
    "\n",
    "[Data Science @ Southern Methodist University](https://datascience.smu.edu/)\n",
    "\n",
    "# Table of Contents\n",
    "* [Team Members](#Team-Members)\n",
    "* [Data Preparation](#Data-Preparation)\n",
    "* [Dataset Description](#Dataset-Description)\n",
    "* [Evaluation Metrics Description](#Evaluation-Metrics-Description)\n",
    "* [Training and Testing Splits method](#Training-Testing)\n",
    "* [Classification Task](#Classification-Task)\n",
    "* [Regression Task](#Regression-Task)\n",
    "* [Methods of Evaluation Results](#Methods-of-Evaluation)\n",
    "* [Advantages of each model](#Advantages-of-each-model)\n",
    "* [Relevant Attributes](#Relevant-Attributes)\n",
    "* [Deployment](#Deployment)\n",
    "* [Exceptional Work](#Exceptional-Work)\n",
    "* [References](#References)\n",
    "\n",
    "\n",
    "# <a name=\"Team-Members\"></a>Team Members\n",
    "* [Jostein Barry-Straume](https://github.com/josteinstraume)\n",
    "* [Kevin Cannon](https://github.com/kcannon2)\n",
    "* [Ernesto Carrera Ruvalcaba](https://github.com/ecarrerasmu)\n",
    "* [Adam Tschannen](https://github.com/adamtschannen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Data-Preparation\"></a>Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [10 points] Define and prepare your class variables. Use proper variable representations (int, float, one-hot, etc.). Use pre-processing methods (as needed) for dimensionality reduction, scaling, etc. Remove variables that are not needed/useful for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import statistics as st\n",
    "import csv as csv\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from __future__ import print_function\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "filepath = \"/data/credit-defaults.xls\"\n",
    "\n",
    "# Relative local path to avoid changing filepath constantly\n",
    "credit = pd.read_excel('../data/credit-defaults.xls', header=1, skiprows=0)\n",
    "\n",
    "\n",
    "# Rename column(s)\n",
    "credit = credit.rename(columns={'default payment next month': 'default_next_m', 'PAY_0': 'PAY_1'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATING NEW VARIABLE TO IMPUTE THE VALUES TO 4, THAT REPRESETNS OTHER\n",
    "credit['EDUCATION_INP']=credit['EDUCATION']\n",
    "\n",
    "credit.loc[credit['EDUCATION'] > 4, 'EDUCATION_INP'] = 4\n",
    "credit.loc[credit['EDUCATION'] == 0, 'EDUCATION_INP'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####FOR MARRIAGE\n",
    "#CREATING NEW VARIABLE TO IMPUTE THE VALUES TO 2, THAT REPRESETNS SINGLE, since the value of 0 is not defined in\n",
    "#the data dictionary\n",
    "credit['MARRIAGE_INP']=credit['MARRIAGE']\n",
    "\n",
    "\n",
    "credit.loc[credit['MARRIAGE'] == 0, 'MARRIAGE_INP'] = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### CREATING A FUNCTION TO GROUP VARIABLES\n",
    "def group_biv_v1(var_name,RangeName,CutOff,NumBins,BinLabel,var_x,var_y,title1,title2):\n",
    "#def bivariate_v1(NumBins): \n",
    "    #Creating the BINS\n",
    "    credit[RangeName]=pd.cut(var_name,CutOff,NumBins,labels=BinLabel)\n",
    "    #Grouping by the BINS variable\n",
    "    default_g=credit.groupby(by=[RangeName])\n",
    "    #% of POPULATION\n",
    "    bins_percentage=default_g[RangeName].count()/credit[RangeName].count()\n",
    "    \n",
    "    #### creating DUMMY VARIABLES\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "#group_biv_v1(credit.PAY_1,'PAY_1_range',[-2.1,0,1,10],3,['Pay duly','delay 1 month ','delay > 1'],'Percentage','PAY_1_bins','% of population PAY_1','Default PAY_1 ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## IMPUTE VALUES FOR THE VARIABLES OF REPAYMENT STATUS (PAY0, PAY1,   PAYN)\n",
    "group_biv_v1(credit.PAY_1,'PAY_1_range',[-2.1,0,1,10],3,['Pay duly','delay 1 month ','delay > 1'],'Percentage','PAY_1_bins','% of population PAY_1','Default PAY_1 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_2,'PAY_2_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_2_bins','% of population PAY_2','Default PAY_2 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_3,'PAY_3_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_3_bins','% of population PAY_3','Default PAY_3 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_4,'PAY_4_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_4_bins','% of population PAY_4','Default PAY_4 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_5,'PAY_5_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_5_bins','% of population PAY_5','Default PAY_5 ')\n",
    "\n",
    "group_biv_v1(credit.PAY_6,'PAY_6_range',[-2.1,1,10],2,['Pay duly','delay > 1'],'Percentage','PAY_6_bins','% of population PAY_6','Default PAY_6 ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default_next_m</th>\n",
       "      <th>EDUCATION_INP</th>\n",
       "      <th>MARRIAGE_INP</th>\n",
       "      <th>PAY_1_range</th>\n",
       "      <th>PAY_2_range</th>\n",
       "      <th>PAY_3_range</th>\n",
       "      <th>PAY_4_range</th>\n",
       "      <th>PAY_5_range</th>\n",
       "      <th>PAY_6_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>delay &gt; 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "      <td>Pay duly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1      20000    2          2         1   24      2      2     -1     -1   \n",
       "1   2     120000    2          2         2   26     -1      2      0      0   \n",
       "2   3      90000    2          2         2   34      0      0      0      0   \n",
       "3   4      50000    2          2         1   37      0      0      0      0   \n",
       "4   5      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "      ...       PAY_AMT6  default_next_m  EDUCATION_INP  MARRIAGE_INP  \\\n",
       "0     ...              0               1              2             1   \n",
       "1     ...           2000               1              2             2   \n",
       "2     ...           5000               0              2             2   \n",
       "3     ...           1000               0              2             1   \n",
       "4     ...            679               0              2             1   \n",
       "\n",
       "   PAY_1_range  PAY_2_range  PAY_3_range  PAY_4_range  PAY_5_range  \\\n",
       "0    delay > 1    delay > 1     Pay duly     Pay duly     Pay duly   \n",
       "1     Pay duly    delay > 1     Pay duly     Pay duly     Pay duly   \n",
       "2     Pay duly     Pay duly     Pay duly     Pay duly     Pay duly   \n",
       "3     Pay duly     Pay duly     Pay duly     Pay duly     Pay duly   \n",
       "4     Pay duly     Pay duly     Pay duly     Pay duly     Pay duly   \n",
       "\n",
       "   PAY_6_range  \n",
       "0     Pay duly  \n",
       "1    delay > 1  \n",
       "2     Pay duly  \n",
       "3     Pay duly  \n",
       "4     Pay duly  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 33 columns):\n",
      "ID                30000 non-null int64\n",
      "LIMIT_BAL         30000 non-null int64\n",
      "SEX               30000 non-null int64\n",
      "EDUCATION         30000 non-null int64\n",
      "MARRIAGE          30000 non-null int64\n",
      "AGE               30000 non-null int64\n",
      "PAY_1             30000 non-null int64\n",
      "PAY_2             30000 non-null int64\n",
      "PAY_3             30000 non-null int64\n",
      "PAY_4             30000 non-null int64\n",
      "PAY_5             30000 non-null int64\n",
      "PAY_6             30000 non-null int64\n",
      "BILL_AMT1         30000 non-null int64\n",
      "BILL_AMT2         30000 non-null int64\n",
      "BILL_AMT3         30000 non-null int64\n",
      "BILL_AMT4         30000 non-null int64\n",
      "BILL_AMT5         30000 non-null int64\n",
      "BILL_AMT6         30000 non-null int64\n",
      "PAY_AMT1          30000 non-null int64\n",
      "PAY_AMT2          30000 non-null int64\n",
      "PAY_AMT3          30000 non-null int64\n",
      "PAY_AMT4          30000 non-null int64\n",
      "PAY_AMT5          30000 non-null int64\n",
      "PAY_AMT6          30000 non-null int64\n",
      "default_next_m    30000 non-null int64\n",
      "EDUCATION_INP     30000 non-null int64\n",
      "MARRIAGE_INP      30000 non-null int64\n",
      "PAY_1_range       30000 non-null category\n",
      "PAY_2_range       30000 non-null category\n",
      "PAY_3_range       30000 non-null category\n",
      "PAY_4_range       30000 non-null category\n",
      "PAY_5_range       30000 non-null category\n",
      "PAY_6_range       30000 non-null category\n",
      "dtypes: category(6), int64(27)\n",
      "memory usage: 6.4 MB\n"
     ]
    }
   ],
   "source": [
    "credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 37 columns):\n",
      "ID                            30000 non-null int64\n",
      "LIMIT_BAL                     30000 non-null int64\n",
      "EDUCATION                     30000 non-null int64\n",
      "MARRIAGE                      30000 non-null int64\n",
      "AGE                           30000 non-null int64\n",
      "PAY_1                         30000 non-null int64\n",
      "PAY_2                         30000 non-null int64\n",
      "PAY_3                         30000 non-null int64\n",
      "PAY_4                         30000 non-null int64\n",
      "PAY_5                         30000 non-null int64\n",
      "PAY_6                         30000 non-null int64\n",
      "BILL_AMT1                     30000 non-null int64\n",
      "BILL_AMT2                     30000 non-null int64\n",
      "BILL_AMT3                     30000 non-null int64\n",
      "BILL_AMT4                     30000 non-null int64\n",
      "BILL_AMT5                     30000 non-null int64\n",
      "BILL_AMT6                     30000 non-null int64\n",
      "PAY_AMT1                      30000 non-null int64\n",
      "PAY_AMT2                      30000 non-null int64\n",
      "PAY_AMT3                      30000 non-null int64\n",
      "PAY_AMT4                      30000 non-null int64\n",
      "PAY_AMT5                      30000 non-null int64\n",
      "PAY_AMT6                      30000 non-null int64\n",
      "default_next_m                30000 non-null int64\n",
      "EDUCATION_INP_2               30000 non-null uint8\n",
      "EDUCATION_INP_3               30000 non-null uint8\n",
      "EDUCATION_INP_4               30000 non-null uint8\n",
      "MARRIAGE_INP_2                30000 non-null uint8\n",
      "MARRIAGE_INP_3                30000 non-null uint8\n",
      "PAY_1_range_delay 1 month     30000 non-null uint8\n",
      "PAY_1_range_delay > 1         30000 non-null uint8\n",
      "PAY_2_range_delay > 1         30000 non-null uint8\n",
      "PAY_3_range_delay > 1         30000 non-null uint8\n",
      "PAY_4_range_delay > 1         30000 non-null uint8\n",
      "PAY_5_range_delay > 1         30000 non-null uint8\n",
      "PAY_6_range_delay > 1         30000 non-null uint8\n",
      "SEX_2                         30000 non-null uint8\n",
      "dtypes: int64(24), uint8(13)\n",
      "memory usage: 5.9 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_1</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>MARRIAGE_INP_2</th>\n",
       "      <th>MARRIAGE_INP_3</th>\n",
       "      <th>PAY_1_range_delay 1 month</th>\n",
       "      <th>PAY_1_range_delay &gt; 1</th>\n",
       "      <th>PAY_2_range_delay &gt; 1</th>\n",
       "      <th>PAY_3_range_delay &gt; 1</th>\n",
       "      <th>PAY_4_range_delay &gt; 1</th>\n",
       "      <th>PAY_5_range_delay &gt; 1</th>\n",
       "      <th>PAY_6_range_delay &gt; 1</th>\n",
       "      <th>SEX_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  EDUCATION  MARRIAGE  AGE  PAY_1  PAY_2  PAY_3  PAY_4  PAY_5  \\\n",
       "0   1      20000          2         1   24      2      2     -1     -1     -2   \n",
       "1   2     120000          2         2   26     -1      2      0      0      0   \n",
       "2   3      90000          2         2   34      0      0      0      0      0   \n",
       "3   4      50000          2         1   37      0      0      0      0      0   \n",
       "4   5      50000          2         1   57     -1      0     -1      0      0   \n",
       "\n",
       "   ...    MARRIAGE_INP_2  MARRIAGE_INP_3  PAY_1_range_delay 1 month   \\\n",
       "0  ...                 0               0                           0   \n",
       "1  ...                 1               0                           0   \n",
       "2  ...                 1               0                           0   \n",
       "3  ...                 0               0                           0   \n",
       "4  ...                 0               0                           0   \n",
       "\n",
       "   PAY_1_range_delay > 1  PAY_2_range_delay > 1  PAY_3_range_delay > 1  \\\n",
       "0                      1                      1                      0   \n",
       "1                      0                      1                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   PAY_4_range_delay > 1  PAY_5_range_delay > 1  PAY_6_range_delay > 1  SEX_2  \n",
       "0                      0                      0                      0      1  \n",
       "1                      0                      0                      1      1  \n",
       "2                      0                      0                      0      1  \n",
       "3                      0                      0                      0      1  \n",
       "4                      0                      0                      0      0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### CREATE DUMMY VARIABLES\n",
    "#Convert Categorical fields to bool using get_dummies\n",
    "#Use drop_first=true to aviod multicolinierarity\n",
    "### The drop_first=true eliminates the first group of the dummy variable\n",
    "### According to the notes provided of the professor we do this to prevent multicollinearity\n",
    "#### I can see it in the context of regression and logistic regression. We may want to select the group to delet\n",
    "##### The method \"get_dummies\" also ELIMINATES THE ORIGINAL VARIABLE TO CREATE THE dummies\n",
    "\n",
    "#EC: Creating  another reference in MEMORY, so the changes in df will not be REFLECTED IN CREDIT\n",
    "df = credit.copy()\n",
    "\n",
    "\n",
    "\n",
    "df = pd.get_dummies(data=credit, \n",
    "                       columns=['EDUCATION_INP',\n",
    "                                'MARRIAGE_INP', \n",
    "                                'PAY_1_range',\n",
    "                                'PAY_2_range',\n",
    "                                'PAY_3_range',\n",
    "                                'PAY_4_range',\n",
    "                                'PAY_5_range',\n",
    "                                'PAY_6_range',\n",
    "                                'SEX'], drop_first=True) #Try drop_first=true to aviod multicolinierarity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.info()\n",
    "\n",
    "df.head()\n",
    "\n",
    "\n",
    "#credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Data columns (total 41 columns):\n",
      "ID                            30000 non-null int64\n",
      "LIMIT_BAL                     30000 non-null int64\n",
      "EDUCATION                     30000 non-null int64\n",
      "MARRIAGE                      30000 non-null int64\n",
      "AGE                           30000 non-null int64\n",
      "PAY_1                         30000 non-null int64\n",
      "PAY_2                         30000 non-null int64\n",
      "PAY_3                         30000 non-null int64\n",
      "PAY_4                         30000 non-null int64\n",
      "PAY_5                         30000 non-null int64\n",
      "PAY_6                         30000 non-null int64\n",
      "BILL_AMT1                     30000 non-null int64\n",
      "BILL_AMT2                     30000 non-null int64\n",
      "BILL_AMT3                     30000 non-null int64\n",
      "BILL_AMT4                     30000 non-null int64\n",
      "BILL_AMT5                     30000 non-null int64\n",
      "BILL_AMT6                     30000 non-null int64\n",
      "PAY_AMT1                      30000 non-null int64\n",
      "PAY_AMT2                      30000 non-null int64\n",
      "PAY_AMT3                      30000 non-null int64\n",
      "PAY_AMT4                      30000 non-null int64\n",
      "PAY_AMT5                      30000 non-null int64\n",
      "PAY_AMT6                      30000 non-null int64\n",
      "default_next_m                30000 non-null int64\n",
      "EDUCATION_INP_2               30000 non-null uint8\n",
      "EDUCATION_INP_3               30000 non-null uint8\n",
      "EDUCATION_INP_4               30000 non-null uint8\n",
      "MARRIAGE_INP_2                30000 non-null uint8\n",
      "MARRIAGE_INP_3                30000 non-null uint8\n",
      "PAY_1_range_delay 1 month     30000 non-null uint8\n",
      "PAY_1_range_delay > 1         30000 non-null uint8\n",
      "PAY_2_range_delay > 1         30000 non-null uint8\n",
      "PAY_3_range_delay > 1         30000 non-null uint8\n",
      "PAY_4_range_delay > 1         30000 non-null uint8\n",
      "PAY_5_range_delay > 1         30000 non-null uint8\n",
      "PAY_6_range_delay > 1         30000 non-null uint8\n",
      "SEX_2                         30000 non-null uint8\n",
      "Avg_BILL                      30000 non-null float64\n",
      "Avg_PAY                       30000 non-null float64\n",
      "AvgBill_to_LIMIT_BAL          30000 non-null float64\n",
      "AvgPay_to_LIMIT_BAL           30000 non-null float64\n",
      "dtypes: float64(4), int64(24), uint8(13)\n",
      "memory usage: 6.8 MB\n"
     ]
    }
   ],
   "source": [
    "##### CREATING ADDITIONAL VARIABLES \n",
    "\n",
    "############## CREATING NEW VARIABLES\n",
    "\n",
    "#average of hte bill amount\n",
    "df['Avg_BILL']=(df['BILL_AMT1']+df['BILL_AMT2']+df['BILL_AMT3']+ df['BILL_AMT4']+df['BILL_AMT5']+df['BILL_AMT6']\n",
    "               )/float(6)\n",
    "\n",
    "\n",
    "#Average of the Payment amount\n",
    "\n",
    "df['Avg_PAY']=(df['PAY_AMT1']+df['PAY_AMT2']+df['PAY_AMT3']+df['PAY_AMT4']+df['PAY_AMT5']+df['PAY_AMT6']\n",
    "               )/float(6)\n",
    "\n",
    "#We are constructing the ratio with the average BILL AMOUNT TO LIMIT\n",
    "df['AvgBill_to_LIMIT_BAL']=(df['Avg_BILL']/df['LIMIT_BAL'])\n",
    "\n",
    "\n",
    "#We are constructing the ratio with the  average PAYMENT AMOUNT TO LIMIT\n",
    "df['AvgPay_to_LIMIT_BAL']=(df['Avg_PAY']/df['LIMIT_BAL'])\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing variables not needed in the analysis\n",
    ">We will conduct one classification task and one regression task. We will create 2 different objects since we will remove different variables\n",
    "\n",
    "> We first create the object for the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### WE CREATE AN OBJECT FOR THE CLASSIFICATION TASK AND OTHER FOR THE REGRESSION TASK\n",
    "\n",
    "# CREATING THE OBJECT FOR THE CLASSIFICATION TASK\n",
    "class_t=df.copy()\n",
    "reg_t=df.copy()\n",
    "\n",
    "if 'default_next_m' in class_t:\n",
    "    y_c = class_t['default_next_m'].values\n",
    "    del class_t['default_next_m']\n",
    "    del class_t['ID']\n",
    "    del class_t['EDUCATION']\n",
    "    del class_t['MARRIAGE']\n",
    "    del class_t['PAY_1']\n",
    "    del class_t['PAY_2']\n",
    "    del class_t['PAY_3']\n",
    "    del class_t['PAY_4']\n",
    "    del class_t['PAY_5']\n",
    "    del class_t['PAY_6']\n",
    "    X_c = class_t.values\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Then we create the object for the Regression Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0642    , 0.02371806, 0.1882463 , ..., 0.39164444, 0.55543958,\n",
       "       0.76958   ])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WE CREATE AN OBJECT FOR THE CLASSIFICATION TASK AND OTHER FOR THE REGRESSION TASK\n",
    "\n",
    "# CREATING THE OBJECT FOR THE REGRESSION  TASK\n",
    "\n",
    "reg_t=df.copy()\n",
    "\n",
    "\n",
    "if 'AvgBill_to_LIMIT_BAL' in reg_t:\n",
    "    y_r = reg_t['AvgBill_to_LIMIT_BAL'].values\n",
    "    del reg_t['AvgBill_to_LIMIT_BAL']\n",
    "    del reg_t['ID']\n",
    "    del reg_t['EDUCATION']\n",
    "    del reg_t['MARRIAGE']\n",
    "    del reg_t['PAY_1']\n",
    "    del reg_t['PAY_2']\n",
    "    del reg_t['PAY_3']\n",
    "    del reg_t['PAY_4']\n",
    "    del reg_t['PAY_5']\n",
    "    del reg_t['PAY_6']\n",
    "    del reg_t['Avg_BILL']\n",
    "    del reg_t['LIMIT_BAL']\n",
    "    del reg_t['AvgPay_to_LIMIT_BAL']\n",
    "    del reg_t['BILL_AMT1']\n",
    "    del reg_t['BILL_AMT2']\n",
    "    del reg_t['BILL_AMT3']\n",
    "    del reg_t['BILL_AMT4']\n",
    "    del reg_t['BILL_AMT5']\n",
    "    del reg_t['BILL_AMT6']\n",
    "    X_r = reg_t.values\n",
    "\n",
    "#len(y_r)\n",
    "y_r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Dataset-Description\"></a>Dataset Description\n",
    "\n",
    ">[5 points] Describe the final dataset that is used for classification/regression (include a description of any newly formed variables you created)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description for the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab1 var for class,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description for the Regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " lab1 + additonal variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Evaluation-Metrics-Description\"></a>Evaluation Metrics Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">[10 points] Choose and explain your evaluation metrics that you will use (i.e., accuracy,\n",
    "precision, recall, F-measure, or any metric we have discussed). Why are the measure(s) appropriate for analyzing the results of your modeling? Give a detailed explanation backing up any assertions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Training-Testing\"></a>Training and Testing Splits method\n",
    "\n",
    ">[10 points] Choose the method you will use for dividing your data into training and testing splits \n",
    "(i.e., are you using Stratified 10-fold cross validation? Why?). Explain why your chosen method is \n",
    "appropriate or use more than one method as appropriate. For example, \n",
    "if you are using time series data then you should be using continuous training and testing sets across time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for classisifations: We chose to use the stratified sampling method becuase our data contains a significantly high number of subjects classified as “0”. Because of this inbalance, there is potential for the algorithm to predict a high number of false negatives and flase  becaue of the class imbalance. The stratified cross validation procedure will ensure the training data sets will have approximately the same amount of subjects who defaulted as those who did not and will subsequently protect the algorithm against false negative predictions\n",
    "\n",
    "for regeression: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINING THE CV OBJECT FOR CLASSIFICATION\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "num_cv_iterations = 3\n",
    "\n",
    "cv_object = StratifiedShuffleSplit(n_splits = num_cv_iterations, \n",
    "                            test_size = 0.20, train_size = 0.80, random_state=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DEFINING THE CV OBJECT FOR REGRESSION\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "#cv = ShuffleSplit(n_splits=10, test_size=0.10, random_state=0)\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "num_cv_iterations = 3\n",
    "\n",
    "cv_reg = ShuffleSplit(n_splits = num_cv_iterations, \n",
    "                            test_size = 0.20, train_size = 0.80, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Classification-Task\"></a>Classification Task\n",
    "\n",
    "> [20 points] Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Regression-Task\"></a>Regression Task\n",
    "\n",
    ">[20 points] Create three different classification/regression models for each task (e.g., random forest, KNN, and SVM for task one and the same or different algorithms for task two). Two modeling techniques must be new (but the third could be SVM or logistic regression). Adjust parameters as appropriate to increase generalization performance using your chosen metric. You must investigate different parameters of the algorithms!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Scorers for Evaluating Regression Models \n",
    "\n",
    "**All regression models created in this notebook are validated using the following metrics:**\n",
    "* Mean Absolute Error (MAE)\n",
    "* Root Mean Squared Error (RMSE) - https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "* Mean Absolute Percentage Error (MAPE) - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "\n",
    "**For details on making scorers to return multiple mean error scores see:**\n",
    "* http://scikit-learn.org/stable/auto_examples/model_selection/plot_multi_metric_evaluation.html\n",
    "* https://github.com/scikit-learn/scikit-learn/pull/7388\n",
    "* https://github.com/drorata/multiscorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SETTING UP THE PERFORMANCE METRICS\n",
    "#Use mean absolute error (MAE) to score the regression models created \n",
    "#(the scale of MAE is identical to the response variable)\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer, mean_squared_error\n",
    "\n",
    "#Function for Root mean squared error\n",
    "#https://stackoverflow.com/questions/17197492/root-mean-square-error-in-python\n",
    "def rmse(y_actual, y_predicted):\n",
    "    return np.sqrt(mean_squared_error(y_actual, y_predicted))\n",
    "\n",
    "#Function for Mean Absolute Percentage Error (MAPE) - Untested\n",
    "#Adapted from - https://stackoverflow.com/questions/42250958/how-to-optimize-mape-code-in-python\n",
    "def mape(y_actual, y_predicted): \n",
    "    mask = y_actual != 0\n",
    "    return (np.fabs(y_actual - y_predicted)/y_actual)[mask].mean() * 100\n",
    "\n",
    "#Create scorers for rmse and mape functions\n",
    "mae_scorer = make_scorer(score_func=mean_absolute_error, greater_is_better=False)\n",
    "rmse_scorer = make_scorer(score_func=rmse, greater_is_better=False)\n",
    "mape_scorer = make_scorer(score_func=mape, greater_is_better=False)\n",
    "\n",
    "#Make scorer array to pass into cross_validate() function for producing mutiple scores for each cv fold.\n",
    "errorScoring = {'MAE':  mae_scorer, \n",
    "                'RMSE': rmse_scorer,\n",
    "                'MAPE': mape_scorer\n",
    "               } "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation\n",
    "** All regression models are evaluated using the regression model evaluation function below: ** \n",
    "* The following regression evaluation function uses the cross validation object and the custom scorers in the two cells above in combination with sklearn.model_selection's cross_validate function to perform cross validation for regression estimators.\n",
    "* The cross validation object above uses a random seed to ensure that all regression estimators are tested on the same randomly selected records for each cross validation fold.\n",
    "* Custom scorers are created using the three chosen mean error scores and passed into cross_validate(), so all three scores are calcualted using a single call to cross_validate().\n",
    "* All of this functionality is wrapped within the custom EvaluateRegressionEstimator() function below so multiple regression models may be tested using the same test / train cv data and evaluation scores producing a consistent output for each model without the need to re-write the same code over and over. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def EvaluateRegressionEstimator(regEstimator, X, y, cv):\n",
    "    \n",
    "    scores = cross_validate(regEstimator, X, y, scoring=errorScoring, cv=cv, return_train_score=True)\n",
    "\n",
    "    #cross val score sign-flips the outputs of MAE\n",
    "    # https://github.com/scikit-learn/scikit-learn/issues/2439\n",
    "    scores['test_MAE'] = scores['test_MAE'] * -1\n",
    "    scores['test_MAPE'] = scores['test_MAPE'] * -1\n",
    "    scores['test_RMSE'] = scores['test_RMSE'] * -1\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    maeAvg = scores['test_MAE'].mean()\n",
    "    print_str = \"The average MAE for all cv folds is: \\t\\t\\t {maeAvg:.5}\"\n",
    "    print(print_str.format(maeAvg=maeAvg))\n",
    "\n",
    "    #print mean test_MAPE for all folds\n",
    "    scores['test_MAPE'] = scores['test_MAPE']\n",
    "    mape_avg = scores['test_MAPE'].mean()\n",
    "    print_str = \"The average MAE percentage (MAPE) for all cv folds is: \\t {mape_avg:.5}\"\n",
    "    print(print_str.format(mape_avg=mape_avg))\n",
    "\n",
    "    #print mean MAE for all folds \n",
    "    RMSEavg = scores['test_RMSE'].mean()\n",
    "    print_str = \"The average RMSE for all cv folds is: \\t\\t\\t {RMSEavg:.5}\"\n",
    "    print(print_str.format(RMSEavg=RMSEavg))\n",
    "    print('*********************************************************')\n",
    "\n",
    "    print('Cross Validation Fold Mean Error Scores')\n",
    "    scoresResults = pd.DataFrame()\n",
    "    scoresResults['MAE'] = scores['test_MAE']\n",
    "    scoresResults['MAPE'] = scores['test_MAPE']\n",
    "    scoresResults['RMSE'] = scores['test_RMSE']\n",
    "    return scoresResults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Regression Model\n",
    "\n",
    "**Linear Regression is used to create a baseline model.  Since linear regression may predict response variable values outside the range of the training data's response variable, we create a linear regression estimator with minority percentage predictions clipped 0% and 100%. For details see:**\n",
    "* http://scikit-learn.org/stable/developers/contributing.html#rolling-your-own-estimator \n",
    "* https://github.com/scikit-learn/scikit-learn/issues/6950\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "* https://github.com/scikit-learn-contrib/project-template/blob/master/skltemplate/template.py\n",
    "* https://stackoverflow.com/questions/44234682/how-to-use-sklearn-when-target-variable-is-a-proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make new estimator compatible for use with GridSearchCV() and cross_validate()\n",
    "# -  Cap predict function for LinearRegression between 0 and 100\n",
    "# -  See: Roll your own estimator links above for details. \n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class CappedLinearRegression(LinearRegression):\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.clip(super(CappedLinearRegression, self).predict(X), 0, 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Grid Search\n",
    "** Here we perform a grid search testing 40 models to find the best parameters for our Linear Regression model based on Mean Absolute Error.  See more on parameter tuning with grid search here:**\n",
    "* http://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  12 out of  12 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=1, test_size=0.2, train_size=0.8),\n",
       "       error_score='raise',\n",
       "       estimator=CappedLinearRegression(copy_X=True, fit_intercept=True, n_jobs=1,\n",
       "            normalize=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'normalize': (True, False), 'fit_intercept': (True, False)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
       "       verbose=1)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a Linear Regression object and perform a grid search to find the best parameters\n",
    "linreg = CappedLinearRegression()\n",
    "parameters = {'normalize':(True,False), 'fit_intercept':(True,False)}\n",
    "\n",
    "#Create a grid search object using the  \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "regGridSearch = GridSearchCV(estimator=linreg\n",
    "                   , verbose=1 # low verbosity\n",
    "                   , param_grid=parameters\n",
    "                   , cv=cv_reg # KFolds = 10\n",
    "                   , scoring=mae_scorer)\n",
    "\n",
    "#Perform hyperparameter search to find the best combination of parameters for our data\n",
    "regGridSearch.fit(X_r, y_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CappedLinearRegression(copy_X=True, fit_intercept=False, n_jobs=1,\n",
       "            normalize=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print the parameterization of the best estimator\n",
    "regGridSearch.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Baseline Regression Model - Cross Validation\n",
    "**Perform tenfold cross validation using the grid search \"best\" parameters and our Capped Linear Regression estimator**\n",
    "* 10-fold cross-validation using the parameters for the top performing model \n",
    "* CAP predictions between 0 and 100% \n",
    "* Evaluate cross-validation results using MAE, MAPE, and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average MAE for all cv folds is: \t\t\t 0.27767\n",
      "The average MAE percentage (MAPE) for all cv folds is: \t -167.99\n",
      "The average RMSE for all cv folds is: \t\t\t 0.33014\n",
      "*********************************************************\n",
      "Cross Validation Fold Mean Error Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.280974</td>\n",
       "      <td>1626.461378</td>\n",
       "      <td>0.336603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.275041</td>\n",
       "      <td>-776.651246</td>\n",
       "      <td>0.324731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276983</td>\n",
       "      <td>-1353.791854</td>\n",
       "      <td>0.329080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MAE         MAPE      RMSE\n",
       "0  0.280974  1626.461378  0.336603\n",
       "1  0.275041  -776.651246  0.324731\n",
       "2  0.276983 -1353.791854  0.329080"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create CappedLinearRegression predictions between 0 and 100% using the best parameters for our Linear Regression object\n",
    "regEstimator = regGridSearch.best_estimator_\n",
    "\n",
    "#Evaluate the regression estimator above using our pre-defined cross validation and scoring metrics. \n",
    "EvaluateRegressionEstimator(regEstimator, X_r, y_r, cv_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Methods-of-Evaluation\"></a>Methods of Evaluation Results\n",
    "\n",
    "> [10 points] Analyze the results using your chosen method of evaluation. Use visualizations of the results to bolster the analysis. Explain any visuals and analyze why they are interesting to someone that might use this model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification: ROC, acc, recall. Regression: mse, acc, rmse, mae mape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Advantages-of-each-model\"></a>Advantages of each model\n",
    ">[10 points] Discuss the advantages of each model for each classification task, if any. If there are not advantages, explain why. Is any model better than another? Is the difference significant with 95% confidence? Use proper statistical comparison methods. You must use statistical comparison techniques—be sure they are appropriate for your chosen method of validation as discussed in unit 7 of the cours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all add your own part. we can clean up after all ideas are put down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Relevant-Attributes\"></a>Relevant Attributes\n",
    ">[10 points] Which attributes from your analysis are most important? Use proper methods discussed in class to evaluate the importance of different attributes. Discuss the results and hypothesize about why certain attributes are more important than others for a given classification task\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all add your own part. we can clean up after all ideas are put down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Deployment\"></a>Deployment\n",
    ">[5 points] How useful is your model for interested parties (i.e., the companies or organizations\n",
    "that might want to use it for prediction)? How would you measure the model's value if it was used by these parties? How would your deploy your model for interested parties? What other data should be collected? How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all add your own part. we can clean up after all ideas are put down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Exceptional-Work\"></a>Exceptional Work\n",
    "> [10 points] You have free reign to provide additional analyses\n",
    "> One idea: grid search parameters in a parallelized fashion and visualize the\n",
    "performances across attributes. Which parameters are most significant for making a good model for each classification algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search- ernesto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a name=\"Training-and-Testing-Split\"></a>Training and Testing Split\n",
    "\n",
    "## Stratified K-Folds Cross-Validation\n",
    "\n",
    "> There is a very apparent class imbalance within the dataset. In order to address this issue, stratified K-Folds cross-validation will be employed to preserve the percentage of samples for each class. In other words, this will prevent the model from simply guessing 'paid duly' for each observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedShuffleSplit(n_splits=3, random_state=1, test_size=0.2,\n",
      "            train_size=0.8)\n",
      "TRAIN: [10029 17540 20357 ..., 13713 29455 19840] TEST: [24380  2508 10431 ...,  1932 21845  7320]\n",
      "TRAIN: [22092 12043 19732 ...,  9586 11830 13420] TEST: [10358  2644  6721 ..., 11354 22402 18779]\n",
      "TRAIN: [20650 10967 12984 ...,  1273 16044 28263] TEST: [23855 28179 26087 ..., 11323 26267  1297]\n"
     ]
    }
   ],
   "source": [
    "#df = credit\n",
    "#EC: Creating  another reference in MEMORY, so the changes in df will not be REFLECTED IN CREDIT\n",
    "#df = credit.copy()\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "if 'default_next_m' in df:\n",
    "    y = df['default_next_m'].values\n",
    "    del df['default_next_m']\n",
    "    del df['ID']\n",
    "    del df['PAY_1']\n",
    "    del df['PAY_2']\n",
    "    del df['PAY_3']\n",
    "    del df['PAY_4']\n",
    "    del df['PAY_5']\n",
    "    del df['PAY_6']\n",
    "    del df['Avg_BILL']\n",
    "    del df['LIMIT_BAL']\n",
    "    del df['AvgPay_to_LIMIT_BAL']\n",
    "    del df['BILL_AMT1']\n",
    "    del df['BILL_AMT2']\n",
    "    del df['BILL_AMT3']\n",
    "    del df['BILL_AMT4']\n",
    "    del df['BILL_AMT5']\n",
    "    del df['BILL_AMT6']\n",
    "    X = df.values\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = StratifiedShuffleSplit(n_splits = num_cv_iterations, \n",
    "                            test_size = 0.20, train_size = 0.80, random_state=1)\n",
    "cv_object.get_n_splits(X, y)\n",
    "print(cv_object)\n",
    "for train_index, test_index in cv_object.split(X, y):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>EDUCATION_INP_2</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_1_range_delay 1 month</th>\n",
       "      <th>PAY_1_range_delay &gt; 1</th>\n",
       "      <th>PAY_2_range_delay &gt; 1</th>\n",
       "      <th>PAY_3_range_delay &gt; 1</th>\n",
       "      <th>PAY_4_range_delay &gt; 1</th>\n",
       "      <th>PAY_5_range_delay &gt; 1</th>\n",
       "      <th>PAY_6_range_delay &gt; 1</th>\n",
       "      <th>SEX_2</th>\n",
       "      <th>Avg_PAY</th>\n",
       "      <th>AvgBill_to_LIMIT_BAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>114.833333</td>\n",
       "      <td>0.064200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>833.333333</td>\n",
       "      <td>0.023718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1836.333333</td>\n",
       "      <td>0.188246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1398.000000</td>\n",
       "      <td>0.771113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9841.500000</td>\n",
       "      <td>0.364463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   EDUCATION  MARRIAGE  AGE  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  \\\n",
       "0          2         1   24         0       689         0         0         0   \n",
       "1          2         2   26         0      1000      1000      1000         0   \n",
       "2          2         2   34      1518      1500      1000      1000      1000   \n",
       "3          2         1   37      2000      2019      1200      1100      1069   \n",
       "4          2         1   57      2000     36681     10000      9000       689   \n",
       "\n",
       "   PAY_AMT6  EDUCATION_INP_2          ...           \\\n",
       "0         0                1          ...            \n",
       "1      2000                1          ...            \n",
       "2      5000                1          ...            \n",
       "3      1000                1          ...            \n",
       "4       679                1          ...            \n",
       "\n",
       "   PAY_1_range_delay 1 month   PAY_1_range_delay > 1  PAY_2_range_delay > 1  \\\n",
       "0                           0                      1                      1   \n",
       "1                           0                      0                      1   \n",
       "2                           0                      0                      0   \n",
       "3                           0                      0                      0   \n",
       "4                           0                      0                      0   \n",
       "\n",
       "   PAY_3_range_delay > 1  PAY_4_range_delay > 1  PAY_5_range_delay > 1  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "   PAY_6_range_delay > 1  SEX_2      Avg_PAY  AvgBill_to_LIMIT_BAL  \n",
       "0                      0      1   114.833333              0.064200  \n",
       "1                      1      1   833.333333              0.023718  \n",
       "2                      0      1  1836.333333              0.188246  \n",
       "3                      0      1  1398.000000              0.771113  \n",
       "4                      0      0  9841.500000              0.364463  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of obs in train set: 24000\n",
      "# of obs in test set: 6000\n",
      "# of defaults in train set: 5309\n",
      "Proportion of defaults in train set: 0.221208333333\n",
      "# of defaults in test set: 1327\n",
      "Proportion of defaults in test set: 0.221166666667\n"
     ]
    }
   ],
   "source": [
    "print('# of obs in train set: ' + str(len(y_train)))\n",
    "print('# of obs in test set: ' + str(len(y_test)))\n",
    "\n",
    "#train_defaults = sum(y_train == 0)\n",
    "train_defaults = sum(y_train == 1)\n",
    "print('# of defaults in train set: ' + str(train_defaults))\n",
    "\n",
    "proportion_train_defaults = train_defaults / len(y_train)\n",
    "print('Proportion of defaults in train set: ' + str(proportion_train_defaults))\n",
    "\n",
    "#test_defaults = sum(y_test == 0)\n",
    "test_defaults = sum(y_test == 1)\n",
    "print('# of defaults in test set: ' + str(test_defaults))\n",
    "\n",
    "proportion_test_defaults = test_defaults / len(y_test)\n",
    "print('Proportion of defaults in test set: ' + str(proportion_test_defaults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of obs in train set: 24000\n",
      "# of obs in test set: 6000\n",
      "# of defaults in train set: 5309\n",
      "Proportion of defaults in train set: 0.221208333333\n",
      "# of defaults in test set: 1327\n",
      "Proportion of defaults in test set: 0.221166666667\n"
     ]
    }
   ],
   "source": [
    "print('# of obs in train set: ' + str(len(y_train)))\n",
    "print('# of obs in test set: ' + str(len(y_test)))\n",
    "\n",
    "#train_defaults = sum(y_train == 0)\n",
    "train_defaults = sum(y_train == 1)\n",
    "print('# of defaults in train set: ' + str(train_defaults))\n",
    "\n",
    "proportion_train_defaults = train_defaults / len(y_train)\n",
    "print('Proportion of defaults in train set: ' + str(proportion_train_defaults))\n",
    "\n",
    "#test_defaults = sum(y_test == 0)\n",
    "test_defaults = sum(y_test == 1)\n",
    "print('# of defaults in test set: ' + str(test_defaults))\n",
    "\n",
    "proportion_test_defaults = test_defaults / len(y_test)\n",
    "print('Proportion of defaults in test set: ' + str(proportion_test_defaults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 5 neighbors is 75.9333333333 %\n",
      "Accuracy of 6 neighbors is 77.8 %\n",
      "Accuracy of 7 neighbors is 77.25 %\n",
      "Accuracy of 8 neighbors is 78.4166666667 %\n",
      "Accuracy of 9 neighbors is 77.8333333333 %\n",
      "Accuracy of 10 neighbors is 78.15 %\n",
      "Accuracy of 11 neighbors is 78.0833333333 %\n",
      "Accuracy of 12 neighbors is 78.25 %\n",
      "Accuracy of 13 neighbors is 78.2166666667 %\n",
      "Accuracy of 14 neighbors is 78.3333333333 %\n",
      "\n",
      "The best accuracy is 0.784167 with 8 neighbor(s)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from IPython.html import widgets \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "max_accs = 0\n",
    "max_k = 0\n",
    "\n",
    "for k in range(5,15):\n",
    "    clf = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='cosine')\n",
    "    clf.fit(X_train, y_train)\n",
    "    yhat = clf.predict(X_test)\n",
    "    acc = mt.accuracy_score(y_test,yhat)\n",
    "    if max(max_accs, acc) == acc:\n",
    "        max_accs = acc\n",
    "        max_k = k\n",
    "    print('Accuracy of', k, 'neighbors is', acc * 100, '%')\n",
    "\n",
    "print('\\nThe best accuracy is %f with %d neighbor(s)'%(max_accs,max_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "\n",
    "for d in ['l1','l2','cosine']:\n",
    "    clf = NearestCentroid(metric=d)\n",
    "    clf.fit(X_train, y_train)\n",
    "    yhat = clf.predict(X_test)\n",
    "    acc = mt.accuracy_score(y_test,yhat)\n",
    "    print('\\nAccuracy of', d, 'metrics is', acc * 100, '%')    \n",
    "    print('The best distance metric is: ', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(penalty='l2', C=1, class_weight='balanced') # get object\n",
    "#WARNING: THE FIRST WIEGHT WAS 1 \n",
    "iter_num=0\n",
    "times_rec=[]\n",
    "for train_indices, test_indices in cv_object.split(X,y): \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "     #we count the time in executing the logistic regression\n",
    "    t0 = time()\n",
    "    \n",
    "    lr_clf.fit(X_train,y_train)  # train object\n",
    "    y_hat = lr_clf.predict(X_test) # get test set precitions\n",
    "    \n",
    "    t1=time()\n",
    "    diff=np.array([t1-t0])\n",
    "    \n",
    "    print (\"The time it takes to fit and predict is \" + str(diff[0]) + \"\\n\")    \n",
    "    times_rec=np.append(times_rec,diff)\n",
    "    \n",
    "\n",
    "    # now let's get the accuracy and confusion matrix for this iterations of training/testing\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    \n",
    "    print(\"\\n *** CLASSIFICATION REPORT ****\")\n",
    "    #### CLASSIFICATION REPORT\n",
    "    ClassReport = mt.classification_report(y_test,y_hat)\n",
    "    print(ClassReport)\n",
    "    \n",
    "    iter_num+=1\n",
    "    \n",
    "    \n",
    "print(\"The average time to fit and predict 3 logistic regressions with 80/20 training/test split is: \" + str(times_rec.mean()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# <a name=\"References\"></a>References\n",
    "\n",
    "* https://github.com/eclarson/DataMiningNotebooks/blob/master/04.%20Logits%20and%20SVM.ipynb\n",
    "* https://github.com/jakemdrew/EducationDataNC/blob/master/Graduation%20Rates%20v2.ipynb\n",
    "* http://scikit-learn.org/stable/modules/cross_validation.html#cross-validation\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "* https://stackoverflow.com/questions/29438265/stratified-train-test-split-in-scikit-learn\n",
    "* http://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
    "* https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
